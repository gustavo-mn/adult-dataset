{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos necessários para o processamento dos dados\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "\n",
    "# Módulos necessários para visualização dos dados\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando os módulos auxiliares\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Divisão de conjunto de treinamento e teste\n",
    "from sklearn.model_selection import cross_validate # Validação cruzada do modelo\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV # Busca pelos melhores hiperparâmetros\n",
    "from sklearn.externals import joblib # Necessário para salvar os modelos treinados em arquivos externos\n",
    "from imblearn.over_sampling import SMOTE # Balanceamento de classes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Métricas de avaliação\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "# Permite que o interpretador de latex (que aceita unicode) seja usado nos textos\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "matplotlib.rcParams['text.latex.unicode'] = False\n",
    "\n",
    "# Função auxiliar para plotar a matriz de confusão. \n",
    "# Retirada de: \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classe real')\n",
    "    plt.xlabel('Classe predita')\n",
    "    \n",
    "def gerar_dataset_balanceado(train_data, \n",
    "                             train_target, \n",
    "                             test_data, \n",
    "                             test_target):\n",
    "    \n",
    "    sm = SMOTE(random_state=0, ratio='minority')\n",
    "    \n",
    "    encoders = list()\n",
    "    \n",
    "    for i in range(2): # Repete duas vezes o loop: um para o conjunto de treino e outro para o de teste\n",
    "        if i == 0:\n",
    "            data = train_data\n",
    "            target = train_target\n",
    "        elif i == 1:\n",
    "            data = test_data\n",
    "            target = test_target\n",
    "    \n",
    "        for feature in train_data.select_dtypes('object').columns:\n",
    "            lb = LabelEncoder()\n",
    "\n",
    "            lb.fit(data[feature])\n",
    "            data[feature] = list(lb.transform(data[feature]))\n",
    "            data[feature] = data[feature].astype('object')\n",
    "\n",
    "            encoders.append(lb)\n",
    "\n",
    "        data_b, target_b = sm.fit_sample(data, target)\n",
    "    #     train_data_b = train_data_b.astype('int64')\n",
    "\n",
    "    #     train_data_b = pd.DataFrame(train_data_b, columns=pd.get_dummies(train_data).columns)\n",
    "        data_b = pd.DataFrame(data_b, columns=data.columns)\n",
    "        data_b['earnings'] = target_b\n",
    "        data_b = data_b.sample(frac=1) # Embaralha os registros\n",
    "\n",
    "        target_b = data_b['earnings']\n",
    "        data_b.drop(columns='earnings', inplace=True)\n",
    "\n",
    "        for idx, feature in enumerate(data.select_dtypes('object').columns):\n",
    "\n",
    "            data[feature] = encoders[idx].inverse_transform(list(data[feature]))\n",
    "\n",
    "            data_b[feature] = data_b[feature].astype('int64')\n",
    "            data_b[feature] = encoders[idx].inverse_transform(list(data_b[feature]))\n",
    "        \n",
    "        if i == 0:\n",
    "            train_data_b = data_b\n",
    "            train_target_b = target_b\n",
    "        elif i == 1:\n",
    "            test_data_b = data_b\n",
    "            test_target_b = target_b\n",
    "    \n",
    "#     test_data_b, test_target_b = sm.fit_sample(pd.get_dummies(test_data), test_target)\n",
    "\n",
    "#     test_data_b = pd.DataFrame(test_data_b, columns=pd.get_dummies(test_data).columns)\n",
    "#     test_data_b['earnings'] = test_target_b\n",
    "#     test_data_b = test_data_b.sample(frac=1) # Embaralha os registros\n",
    "    \n",
    "#     test_target_b = test_data_b['earnings']\n",
    "#     test_data_b.drop(columns='earnings', inplace=True)\n",
    "    \n",
    "    return train_data_b, train_target_b, test_data_b, test_target_b\n",
    "\n",
    "def exibir_resultados_finais(clf, \n",
    "                             test_data, \n",
    "                             test_target, \n",
    "                             id_abordagem, \n",
    "                             str_balanceamento, \n",
    "                             path_arquivos,\n",
    "                             tipo_classificador,\n",
    "                             fracao_dataset=0.1,\n",
    "                             salvar_resultados=False):\n",
    "    \n",
    "    matplotlib.rcParams['text.usetex'] = False\n",
    "    matplotlib.rcParams['text.latex.unicode'] = False\n",
    "    \n",
    "    # Classificando o conjunto de teste\n",
    "\n",
    "    predicoes = clf.predict(test_data)\n",
    "\n",
    "    if tipo_classificador == 'arvore':\n",
    "    \n",
    "        # Salvando a árvore treinada graficamente\n",
    "\n",
    "        export_graphviz(clf, \n",
    "                        out_file=path_arquivos+tipo_classificador+'-final-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "                        feature_names=test_data.columns,  \n",
    "                        class_names=['Less than or equal to', 'More than'],  \n",
    "                        filled=True, rounded=True,  \n",
    "                        special_characters=True)  \n",
    "\n",
    "    # Avaliando o desempenho\n",
    "\n",
    "    # Matriz de confusão\n",
    "\n",
    "    cfs_mtx = confusion_matrix(test_target, predicoes)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.set(font_scale=2)\n",
    "    ax = sns.heatmap(cfs_mtx, \n",
    "                     xticklabels=['$\\leq50$K', '$>50$K'], \n",
    "                     yticklabels=['$\\leq50$K', '$>50$K'], \n",
    "                     annot=cfs_mtx,\n",
    "                     fmt='d',\n",
    "                     cbar=None)\n",
    "\n",
    "    ax.set_xlabel('Predito', labelpad=20, fontsize=30)\n",
    "    ax.set_ylabel('Real', labelpad=20, fontsize=30)\n",
    "    ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "    acc = accuracy_score(test_target, predicoes)\n",
    "    pre = precision_score(test_target, predicoes)\n",
    "    rec = recall_score(test_target, predicoes)\n",
    "    f1 = f1_score(test_target, predicoes)\n",
    "    \n",
    "    if tipo_classificador in ['svm-rbf','svm-linear']:\n",
    "        predicoes = clf.decision_function(test_data)\n",
    "    elif tipo_classificador in ['arvore','naive-bayes','logit','knn','rf']:\n",
    "        predicoes = clf.predict_proba(test_data)[:,1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(test_target, predicoes)\n",
    "    prc_auc = average_precision_score(test_target, predicoes)\n",
    "\n",
    "    print('Acurácia: %.3f %%' % (acc*100))\n",
    "    print('Precisão: %.3f %%' % (pre*100))\n",
    "    print('Recall: %.3f %%' % (rec*100))\n",
    "    print('F1 score: %3f %%' % (f1*100))\n",
    "    print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "    print('PRC AUC: %.3f %%' % (prc_auc*100))\n",
    "\n",
    "    # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "    \n",
    "    if salvar_resultados:\n",
    "        if tipo_classificador == 'arvore':\n",
    "            path_graficos = 'Classificadores/Arvores-decisao/'\n",
    "        elif tipo_classificador in ['svm-linear', 'svm-rbf']:\n",
    "            path_graficos = 'Classificadores/SVM/'\n",
    "        elif tipo_classificador == 'naive-bayes':\n",
    "            path_graficos = 'Classificadores/Naive-bayes/'\n",
    "        elif tipo_classificador == 'logit':\n",
    "            path_graficos = 'Classificadores/Regressao-logistica/'\n",
    "            \n",
    "        joblib.dump(predicoes,\n",
    "                    path_arquivos+tipo_classificador+'-final-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-predicoes.pkl')    \n",
    "        \n",
    "        filename = path_graficos+tipo_classificador+'-final-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-matriz-confusao.png'\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "        d = {'Acuracia': acc, \n",
    "             'Precisao': pre, \n",
    "             'Recall': rec, \n",
    "             'F1': f1,\n",
    "             'ROC AUC': roc_auc, \n",
    "             'PRC AUC': prc_auc}\n",
    "        \n",
    "        temp = pd.Series(data=d).to_csv(path=path_arquivos+tipo_classificador+'-final-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-medidas.csv', sep=',')\n",
    "        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    matplotlib.rcParams['text.usetex'] = False\n",
    "    matplotlib.rcParams['text.latex.unicode'] = False\n",
    "    \n",
    "def gerarTabelaResultadosCVRedeNeural(metricas, param_range):\n",
    "\n",
    "    # Tabela com resultados de treino\n",
    "\n",
    "    tb_train = pd.DataFrame(columns=['split'+str(i)+'_train_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    for n_comb_param in range(0,len(param_range)):\n",
    "        idx_vetores = -1\n",
    "        for idx2,col in enumerate(tb_train.columns):\n",
    "            if idx2%3 == 0:\n",
    "                idx_vetores += 1\n",
    "                vetor = train_scores_acc\n",
    "            elif idx2%3 == 1:\n",
    "                vetor = train_scores_f1\n",
    "            elif idx2%3 == 2:\n",
    "                vetor = train_scores_roc\n",
    "\n",
    "            tb_train.loc[n_comb_param,col] = vetor[idx_vetores]\n",
    "\n",
    "    # Tabela com resultados de validação\n",
    "\n",
    "    tb_val = pd.DataFrame(columns=['split'+str(i)+'_test_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    for n_comb_param in range(0,len(param_range)):\n",
    "        idx_vetores = -1\n",
    "        for idx2,col in enumerate(tb_val.columns):\n",
    "            if idx2%3 == 0:\n",
    "                idx_vetores += 1\n",
    "                vetor = val_scores_acc\n",
    "            elif idx2%3 == 1:\n",
    "                vetor = val_scores_f1\n",
    "            elif idx2%3 == 2:\n",
    "                vetor = val_scores_roc\n",
    "\n",
    "            tb_val.loc[n_comb_param,col] = vetor[idx_vetores]\n",
    "\n",
    "    # Concatenação das duas tabelas\n",
    "\n",
    "    tb = pd.concat([tb_train, tb_val], axis=1)\n",
    "\n",
    "    # Adicionando as colunas com os parâmetros\n",
    "\n",
    "    tb['param_n_neuronios'] = param_range\n",
    "    \n",
    "    return tb\n",
    "\n",
    "def gerarLinhaTabelaResultadosCVRedeNeural(metricas, \n",
    "                                           n_splits,\n",
    "                                           train_scores_acc, \n",
    "                                           train_scores_pre,\n",
    "                                           train_scores_rec,\n",
    "                                           train_scores_f1,\n",
    "                                           train_scores_roc,\n",
    "                                           val_scores_acc,\n",
    "                                           val_scores_pre,\n",
    "                                           val_scores_rec,\n",
    "                                           val_scores_f1,\n",
    "                                           val_scores_roc):\n",
    "\n",
    "    # Tabela com resultados de treino\n",
    "\n",
    "    tb_train = pd.DataFrame(columns=['split'+str(i)+'_train_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    idx_vetores = -1\n",
    "    for idx2,col in enumerate(tb_train.columns):\n",
    "        if idx2%5 == 0:\n",
    "            idx_vetores += 1\n",
    "            vetor = train_scores_acc\n",
    "        elif idx2%5 == 1:\n",
    "            vetor = train_scores_pre\n",
    "        elif idx2%5 == 2:\n",
    "            vetor = train_scores_rec\n",
    "        elif idx2%5 == 3:\n",
    "            vetor = train_scores_f1\n",
    "        elif idx2%5 == 4:\n",
    "            vetor = train_scores_roc\n",
    "\n",
    "        tb_train.loc[0,col] = vetor[idx_vetores]\n",
    "\n",
    "    # Tabela com resultados de validação\n",
    "\n",
    "    tb_val = pd.DataFrame(columns=['split'+str(i)+'_test_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    idx_vetores = -1\n",
    "    for idx2,col in enumerate(tb_val.columns):\n",
    "        if idx2%5 == 0:\n",
    "            idx_vetores += 1\n",
    "            vetor = val_scores_acc\n",
    "        elif idx2%5 == 1:\n",
    "            vetor = val_scores_pre\n",
    "        elif idx2%5 == 2:\n",
    "            vetor = val_scores_rec\n",
    "        elif idx2%5 == 3:\n",
    "            vetor = val_scores_f1\n",
    "        elif idx2%5 == 4:\n",
    "            vetor = val_scores_roc\n",
    "\n",
    "        tb_val.loc[0,col] = vetor[idx_vetores]\n",
    "\n",
    "    # Concatenação das duas tabelas\n",
    "\n",
    "    tb = pd.concat([tb_train, tb_val], axis=1)\n",
    "\n",
    "#     # Adicionando as colunas com os parâmetros\n",
    "\n",
    "#     tb['param_n_neuronios'] = param_range\n",
    "    \n",
    "    return tb.values\n",
    "\n",
    "\n",
    "# ATENÇÃO!!! Escolher corretamente qual a fração do dataset que está sendo utilizada\n",
    "\n",
    "fracao_dataset = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/netware/users/gustavomn/.conda/envs/data-mining-coc800/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Importando os arquivos com os datasets pré-processados\n",
    "\n",
    "path_arquivos = 'Data/'\n",
    "\n",
    "data_pre_proc_1 = pd.read_csv(path_arquivos+'data-pre-proc-1.csv')\n",
    "data_pre_proc_2 = pd.read_csv(path_arquivos+'data-pre-proc-2.csv')\n",
    "data_pre_proc_3 = pd.read_csv(path_arquivos+'data-pre-proc-3.csv')\n",
    "data_pre_proc_4 = pd.read_csv(path_arquivos+'data-pre-proc-4.csv')\n",
    "\n",
    "# Descartando a primeira coluna, que é só identificador do registro\n",
    "\n",
    "data_pre_proc_1 = data_pre_proc_1.iloc[:,1::]\n",
    "data_pre_proc_2 = data_pre_proc_2.iloc[:,1::]\n",
    "data_pre_proc_3 = data_pre_proc_3.iloc[:,1::]\n",
    "data_pre_proc_4 = data_pre_proc_4.iloc[:,1::]\n",
    "\n",
    "# Separando o target e dividindo os conjuntos de treino e teste para cada dataset\n",
    "\n",
    "# Dataset 1\n",
    "\n",
    "target_1 = data_pre_proc_1['earnings']\n",
    "data_pre_proc_1.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_1, test_data_1, train_target_1, test_target_1 = train_test_split(\n",
    "    data_pre_proc_1, target_1, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_1, train_target_b_1, test_data_b_1, test_target_b_1 = gerar_dataset_balanceado(\n",
    "    train_data_1, train_target_1, test_data_1, test_target_1)\n",
    "\n",
    "# Dataset 2\n",
    "\n",
    "target_2 = data_pre_proc_2['earnings']\n",
    "data_pre_proc_2.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_2, test_data_2, train_target_2, test_target_2 = train_test_split(\n",
    "    data_pre_proc_2, target_2, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_2, train_target_b_2, test_data_b_2, test_target_b_2 = gerar_dataset_balanceado(\n",
    "    train_data_2, train_target_2, test_data_2, test_target_2)\n",
    "    \n",
    "# Dataset 3\n",
    "    \n",
    "target_3 = data_pre_proc_3['earnings']\n",
    "data_pre_proc_3.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_3, test_data_3, train_target_3, test_target_3 = train_test_split(\n",
    "    data_pre_proc_3, target_3, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_3, train_target_b_3, test_data_b_3, test_target_b_3 = gerar_dataset_balanceado(\n",
    "    train_data_3, train_target_3, test_data_3, test_target_3)\n",
    "    \n",
    "# Dataset 4    \n",
    "\n",
    "target_4 = data_pre_proc_4['earnings']\n",
    "data_pre_proc_4.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_4, test_data_4, train_target_4, test_target_4 = train_test_split(\n",
    "    data_pre_proc_4, target_4, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_4, train_target_b_4, test_data_b_4, test_target_b_4 = gerar_dataset_balanceado(\n",
    "    train_data_4, train_target_4, test_data_4, test_target_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando a distribuição dos targets em cada conjunto (treino e teste) de cada abordagem\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "temp_train = [train_target_1, train_target_2, train_target_3, train_target_4]\n",
    "temp_test = [test_target_1, test_target_2, test_target_3, test_target_4]\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    ax = temp_train[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_train[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Treino ' + str(i+1))\n",
    "#     plt.show()\n",
    "\n",
    "#     fig = plt.figure(figsize=(30,15))\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    ax = temp_test[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_test[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Teste ' + str(i+1))\n",
    "#     plt.show()\n",
    "\n",
    "temp_train_b = [train_target_b_1, train_target_b_2, train_target_b_3, train_target_b_4]\n",
    "temp_test_b = [test_target_b_1, test_target_b_2, test_target_b_3, test_target_b_4]\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    ax = temp_train_b[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_train_b[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Treino ' + str(i+1))\n",
    "#     plt.show()\n",
    "\n",
    "#     fig = plt.figure(figsize=(30,15))\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    ax = temp_test_b[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_test_b[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Teste ' + str(i+1))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1635/1635 [==============================] - 0s 219us/step - loss: 0.5471 - acc: 0.7737\n",
      "Epoch 2/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.5025 - acc: 0.7737\n",
      "Epoch 3/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.4715 - acc: 0.7737\n",
      "Epoch 4/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.4470 - acc: 0.7737\n",
      "Epoch 5/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.4295 - acc: 0.7737\n",
      "Epoch 6/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.4170 - acc: 0.7737\n",
      "Epoch 7/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.4078 - acc: 0.7737\n",
      "Epoch 8/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.4003 - acc: 0.7737\n",
      "Epoch 9/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3946 - acc: 0.7792\n",
      "Epoch 10/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3896 - acc: 0.7878\n",
      "Epoch 11/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3852 - acc: 0.7969\n",
      "Epoch 12/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3813 - acc: 0.8116\n",
      "Epoch 13/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3780 - acc: 0.8190\n",
      "Epoch 14/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3744 - acc: 0.8263\n",
      "Epoch 15/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3717 - acc: 0.8312\n",
      "Epoch 16/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3690 - acc: 0.8391\n",
      "Epoch 17/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3665 - acc: 0.8410\n",
      "Epoch 18/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3642 - acc: 0.8446\n",
      "Epoch 19/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3622 - acc: 0.8471\n",
      "Epoch 20/4000\n",
      "1635/1635 [==============================] - 0s 103us/step - loss: 0.3603 - acc: 0.8453\n",
      "Epoch 21/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3582 - acc: 0.8477\n",
      "Epoch 22/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3566 - acc: 0.8453\n",
      "Epoch 23/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3549 - acc: 0.8489\n",
      "Epoch 24/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3534 - acc: 0.8465\n",
      "Epoch 25/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3523 - acc: 0.8440\n",
      "Epoch 26/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3509 - acc: 0.8440\n",
      "Epoch 27/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3494 - acc: 0.8440\n",
      "Epoch 28/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3484 - acc: 0.8465\n",
      "Epoch 29/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3475 - acc: 0.8477\n",
      "Epoch 30/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3461 - acc: 0.8477\n",
      "Epoch 31/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3453 - acc: 0.8453\n",
      "Epoch 32/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3442 - acc: 0.8502\n",
      "Epoch 33/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3434 - acc: 0.8459\n",
      "Epoch 34/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3425 - acc: 0.8489\n",
      "Epoch 35/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3419 - acc: 0.8477\n",
      "Epoch 36/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3411 - acc: 0.8495\n",
      "Epoch 37/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3404 - acc: 0.8520\n",
      "Epoch 38/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3401 - acc: 0.8483\n",
      "Epoch 39/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3390 - acc: 0.8483\n",
      "Epoch 40/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3383 - acc: 0.8508\n",
      "Epoch 41/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3377 - acc: 0.8526\n",
      "Epoch 42/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3374 - acc: 0.8520\n",
      "Epoch 43/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3366 - acc: 0.8514\n",
      "Epoch 44/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3360 - acc: 0.8526\n",
      "Epoch 45/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3356 - acc: 0.8502\n",
      "Epoch 46/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3351 - acc: 0.8538\n",
      "Epoch 47/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3345 - acc: 0.8538\n",
      "Epoch 48/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3341 - acc: 0.8520\n",
      "Epoch 49/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3338 - acc: 0.8526\n",
      "Epoch 50/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3331 - acc: 0.8538\n",
      "Epoch 51/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3329 - acc: 0.8532\n",
      "Epoch 52/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3324 - acc: 0.8550\n",
      "Epoch 53/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3319 - acc: 0.8538\n",
      "Epoch 54/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3317 - acc: 0.8581\n",
      "Epoch 55/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3314 - acc: 0.8563\n",
      "Epoch 56/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3308 - acc: 0.8569\n",
      "Epoch 57/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3305 - acc: 0.8550\n",
      "Epoch 58/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3301 - acc: 0.8575\n",
      "Epoch 59/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3298 - acc: 0.8526\n",
      "Epoch 60/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3296 - acc: 0.8544\n",
      "Epoch 61/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3295 - acc: 0.8526\n",
      "Epoch 62/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3290 - acc: 0.8557\n",
      "Epoch 63/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3286 - acc: 0.8544\n",
      "Epoch 64/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3284 - acc: 0.8581\n",
      "Epoch 65/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3283 - acc: 0.8557\n",
      "Epoch 66/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3278 - acc: 0.8563\n",
      "Epoch 67/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3277 - acc: 0.8575\n",
      "Epoch 68/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3273 - acc: 0.8569\n",
      "Epoch 69/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3269 - acc: 0.8593\n",
      "Epoch 70/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3270 - acc: 0.8557\n",
      "Epoch 71/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3268 - acc: 0.8557\n",
      "Epoch 72/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3266 - acc: 0.8575\n",
      "Epoch 73/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3261 - acc: 0.8550\n",
      "Epoch 74/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3262 - acc: 0.8581\n",
      "Epoch 75/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3259 - acc: 0.8581\n",
      "Epoch 76/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3258 - acc: 0.8563\n",
      "Epoch 77/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3260 - acc: 0.8581\n",
      "Epoch 78/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3255 - acc: 0.8569\n",
      "Epoch 79/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3250 - acc: 0.8557\n",
      "Epoch 80/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3252 - acc: 0.8569\n",
      "Epoch 81/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3249 - acc: 0.8557\n",
      "Epoch 82/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3250 - acc: 0.8581\n",
      "Epoch 83/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3247 - acc: 0.8550\n",
      "Epoch 84/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3245 - acc: 0.8557\n",
      "Epoch 85/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3245 - acc: 0.8557\n",
      "Epoch 86/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3242 - acc: 0.8581\n",
      "Epoch 87/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3240 - acc: 0.8593\n",
      "Epoch 88/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3239 - acc: 0.8557\n",
      "Epoch 89/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3238 - acc: 0.8550\n",
      "Epoch 90/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3236 - acc: 0.8550\n",
      "Epoch 91/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3235 - acc: 0.8575\n",
      "Epoch 92/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3233 - acc: 0.8569\n",
      "Epoch 93/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3233 - acc: 0.8563\n",
      "Epoch 94/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3233 - acc: 0.8544\n",
      "Epoch 95/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3229 - acc: 0.8569\n",
      "Epoch 96/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3228 - acc: 0.8575\n",
      "Epoch 97/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3232 - acc: 0.8526\n",
      "Epoch 98/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3225 - acc: 0.8563\n",
      "Epoch 99/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3225 - acc: 0.8569\n",
      "Epoch 100/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3229 - acc: 0.8581\n",
      "Epoch 101/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3223 - acc: 0.8575\n",
      "Epoch 102/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3222 - acc: 0.8575\n",
      "Epoch 103/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3222 - acc: 0.8587\n",
      "Epoch 104/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3220 - acc: 0.8569\n",
      "Epoch 105/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3219 - acc: 0.8599\n",
      "Epoch 106/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3223 - acc: 0.8581\n",
      "Epoch 107/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3217 - acc: 0.8587\n",
      "Epoch 108/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3215 - acc: 0.8599\n",
      "Epoch 109/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3214 - acc: 0.8587\n",
      "Epoch 110/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3216 - acc: 0.8599\n",
      "Epoch 111/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3212 - acc: 0.8593\n",
      "Epoch 112/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3215 - acc: 0.8569\n",
      "Epoch 113/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3214 - acc: 0.8575\n",
      "Epoch 114/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3209 - acc: 0.8575\n",
      "Epoch 115/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3209 - acc: 0.8575\n",
      "Epoch 116/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3205 - acc: 0.8575\n",
      "Epoch 117/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3207 - acc: 0.8599\n",
      "Epoch 118/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3205 - acc: 0.8599\n",
      "Epoch 119/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3206 - acc: 0.8593\n",
      "Epoch 120/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3204 - acc: 0.8599\n",
      "Epoch 121/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3204 - acc: 0.8575\n",
      "Epoch 122/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3202 - acc: 0.8581\n",
      "Epoch 123/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3201 - acc: 0.8569\n",
      "Epoch 124/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3206 - acc: 0.8587\n",
      "Epoch 125/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3199 - acc: 0.8587\n",
      "Epoch 126/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3198 - acc: 0.8587\n",
      "Epoch 127/4000\n",
      "1635/1635 [==============================] - 0s 108us/step - loss: 0.3199 - acc: 0.8563\n",
      "Epoch 128/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3198 - acc: 0.8569\n",
      "Epoch 129/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3196 - acc: 0.8575\n",
      "Epoch 130/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3195 - acc: 0.8569\n",
      "Epoch 131/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3198 - acc: 0.8575\n",
      "Epoch 132/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3193 - acc: 0.8569\n",
      "Epoch 133/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3194 - acc: 0.8599\n",
      "Epoch 134/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3194 - acc: 0.8612\n",
      "Epoch 135/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3192 - acc: 0.8587\n",
      "Epoch 136/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3190 - acc: 0.8587\n",
      "Epoch 137/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3188 - acc: 0.8581\n",
      "Epoch 138/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3189 - acc: 0.8599\n",
      "Epoch 139/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3191 - acc: 0.8581\n",
      "Epoch 140/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3187 - acc: 0.8606\n",
      "Epoch 141/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3187 - acc: 0.8593\n",
      "Epoch 142/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3188 - acc: 0.8606\n",
      "Epoch 143/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3189 - acc: 0.8618\n",
      "Epoch 144/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3185 - acc: 0.8599\n",
      "Epoch 145/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3184 - acc: 0.8593\n",
      "Epoch 146/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3181 - acc: 0.8599\n",
      "Epoch 147/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3180 - acc: 0.8581\n",
      "Epoch 148/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3183 - acc: 0.8606\n",
      "Epoch 149/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3183 - acc: 0.8612\n",
      "Epoch 150/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3182 - acc: 0.8606\n",
      "Epoch 151/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3182 - acc: 0.8630\n",
      "Epoch 152/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3183 - acc: 0.8593\n",
      "Epoch 153/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3185 - acc: 0.8593\n",
      "Epoch 154/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3180 - acc: 0.8587\n",
      "Epoch 155/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3175 - acc: 0.8599\n",
      "Epoch 156/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3174 - acc: 0.8624\n",
      "Epoch 157/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3177 - acc: 0.8593\n",
      "Epoch 158/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3176 - acc: 0.8599\n",
      "Epoch 159/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3174 - acc: 0.8606\n",
      "Epoch 160/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3173 - acc: 0.8599\n",
      "Epoch 161/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3174 - acc: 0.8599\n",
      "Epoch 162/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3173 - acc: 0.8599\n",
      "Epoch 163/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3168 - acc: 0.8593\n",
      "Epoch 164/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3172 - acc: 0.8599\n",
      "Epoch 165/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3170 - acc: 0.8648\n",
      "Epoch 166/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3175 - acc: 0.8612\n",
      "Epoch 167/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3170 - acc: 0.8618\n",
      "Epoch 168/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3168 - acc: 0.8618\n",
      "Epoch 169/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3170 - acc: 0.8612\n",
      "Epoch 170/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3167 - acc: 0.8612\n",
      "Epoch 171/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3166 - acc: 0.8624\n",
      "Epoch 172/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3172 - acc: 0.8636\n",
      "Epoch 173/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3166 - acc: 0.8636\n",
      "Epoch 174/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3164 - acc: 0.8624\n",
      "Epoch 175/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3162 - acc: 0.8606\n",
      "Epoch 176/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3163 - acc: 0.8642\n",
      "Epoch 177/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3163 - acc: 0.8599\n",
      "Epoch 178/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3160 - acc: 0.8630\n",
      "Epoch 179/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3165 - acc: 0.8618\n",
      "Epoch 180/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3164 - acc: 0.8624\n",
      "Epoch 181/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3160 - acc: 0.8618\n",
      "Epoch 182/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3159 - acc: 0.8624\n",
      "Epoch 183/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3162 - acc: 0.8630\n",
      "Epoch 184/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3158 - acc: 0.8606\n",
      "Epoch 185/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3159 - acc: 0.8630\n",
      "Epoch 186/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3156 - acc: 0.8606\n",
      "Epoch 187/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3156 - acc: 0.8612\n",
      "Epoch 188/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3160 - acc: 0.8587\n",
      "Epoch 189/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3153 - acc: 0.8612\n",
      "Epoch 190/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3155 - acc: 0.8624\n",
      "Epoch 191/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3154 - acc: 0.8636\n",
      "Epoch 192/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3153 - acc: 0.8624\n",
      "Epoch 193/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3152 - acc: 0.8612\n",
      "Epoch 194/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3151 - acc: 0.8630\n",
      "Epoch 195/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3151 - acc: 0.8618\n",
      "Epoch 196/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3152 - acc: 0.8593\n",
      "Epoch 197/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3151 - acc: 0.8618\n",
      "Epoch 198/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3151 - acc: 0.8618\n",
      "Epoch 199/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3150 - acc: 0.8624\n",
      "Epoch 200/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3147 - acc: 0.8630\n",
      "Epoch 201/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3147 - acc: 0.8612\n",
      "Epoch 202/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3152 - acc: 0.8606\n",
      "Epoch 203/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3152 - acc: 0.8606\n",
      "Epoch 204/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3146 - acc: 0.8612\n",
      "Epoch 205/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3148 - acc: 0.8630\n",
      "Epoch 206/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3142 - acc: 0.8612\n",
      "Epoch 207/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3144 - acc: 0.8624\n",
      "Epoch 208/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3144 - acc: 0.8618\n",
      "Epoch 209/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3144 - acc: 0.8618\n",
      "Epoch 210/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3143 - acc: 0.8612\n",
      "Epoch 211/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3142 - acc: 0.8636\n",
      "Epoch 212/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3145 - acc: 0.8636\n",
      "Epoch 213/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3140 - acc: 0.8642\n",
      "Epoch 214/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3145 - acc: 0.8618\n",
      "Epoch 215/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3140 - acc: 0.8618\n",
      "Epoch 216/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3144 - acc: 0.8636\n",
      "Epoch 217/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3135 - acc: 0.8642\n",
      "Epoch 218/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3140 - acc: 0.8630\n",
      "Epoch 219/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3139 - acc: 0.8606\n",
      "Epoch 220/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3143 - acc: 0.8612\n",
      "Epoch 221/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3134 - acc: 0.8648\n",
      "Epoch 222/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3142 - acc: 0.8636\n",
      "Epoch 223/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3135 - acc: 0.8606\n",
      "Epoch 224/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3135 - acc: 0.8618\n",
      "Epoch 225/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3139 - acc: 0.8636\n",
      "Epoch 226/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3140 - acc: 0.8618\n",
      "Epoch 227/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3133 - acc: 0.8630\n",
      "Epoch 228/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3133 - acc: 0.8612\n",
      "Epoch 229/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3138 - acc: 0.8618\n",
      "Epoch 230/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3136 - acc: 0.8630\n",
      "Epoch 231/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3130 - acc: 0.8636\n",
      "Epoch 232/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3132 - acc: 0.8654\n",
      "Epoch 233/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3132 - acc: 0.8654\n",
      "Epoch 234/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3129 - acc: 0.8624\n",
      "Epoch 235/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3129 - acc: 0.8636\n",
      "Epoch 236/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3129 - acc: 0.8636\n",
      "Epoch 237/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3130 - acc: 0.8642\n",
      "Epoch 238/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3129 - acc: 0.8654\n",
      "Epoch 239/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3131 - acc: 0.8630\n",
      "Epoch 240/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3128 - acc: 0.8661\n",
      "Epoch 241/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3126 - acc: 0.8642\n",
      "Epoch 242/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3127 - acc: 0.8630\n",
      "Epoch 243/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3125 - acc: 0.8630\n",
      "Epoch 244/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3126 - acc: 0.8636\n",
      "Epoch 245/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3127 - acc: 0.8624\n",
      "Epoch 246/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3131 - acc: 0.8642\n",
      "Epoch 247/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3126 - acc: 0.8667\n",
      "Epoch 248/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3125 - acc: 0.8654\n",
      "Epoch 249/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3126 - acc: 0.8642\n",
      "Epoch 250/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3126 - acc: 0.8654\n",
      "Epoch 251/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3124 - acc: 0.8667\n",
      "Epoch 252/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3125 - acc: 0.8636\n",
      "Epoch 253/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3121 - acc: 0.8661\n",
      "Epoch 254/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3121 - acc: 0.8636\n",
      "Epoch 255/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3120 - acc: 0.8648\n",
      "Epoch 256/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3121 - acc: 0.8648\n",
      "Epoch 257/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3121 - acc: 0.8648\n",
      "Epoch 258/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3119 - acc: 0.8636\n",
      "Epoch 259/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3122 - acc: 0.8618\n",
      "Epoch 260/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3123 - acc: 0.8667\n",
      "Epoch 261/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3120 - acc: 0.8636\n",
      "Epoch 262/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3118 - acc: 0.8630\n",
      "Epoch 263/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3119 - acc: 0.8679\n",
      "Epoch 264/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3117 - acc: 0.8661\n",
      "Epoch 265/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3117 - acc: 0.8642\n",
      "Epoch 266/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3120 - acc: 0.8642\n",
      "Epoch 267/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3118 - acc: 0.8648\n",
      "Epoch 268/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3116 - acc: 0.8636\n",
      "Epoch 269/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3122 - acc: 0.8667\n",
      "Epoch 270/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3114 - acc: 0.8648\n",
      "Epoch 271/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3119 - acc: 0.8661\n",
      "Epoch 272/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3115 - acc: 0.8673\n",
      "Epoch 273/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3113 - acc: 0.8654\n",
      "Epoch 274/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3115 - acc: 0.8667\n",
      "Epoch 275/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3115 - acc: 0.8648\n",
      "Epoch 276/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3113 - acc: 0.8654\n",
      "Epoch 277/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3114 - acc: 0.8654\n",
      "Epoch 278/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3114 - acc: 0.8667\n",
      "Epoch 279/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3114 - acc: 0.8612\n",
      "Epoch 280/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3112 - acc: 0.8642\n",
      "Epoch 281/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3110 - acc: 0.8661\n",
      "Epoch 282/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3109 - acc: 0.8654\n",
      "Epoch 283/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3111 - acc: 0.8661\n",
      "Epoch 284/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3114 - acc: 0.8661\n",
      "Epoch 285/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3111 - acc: 0.8673\n",
      "Epoch 286/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3108 - acc: 0.8654\n",
      "Epoch 287/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3113 - acc: 0.8642\n",
      "Epoch 288/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3112 - acc: 0.8679\n",
      "Epoch 289/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3108 - acc: 0.8642\n",
      "Epoch 290/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3110 - acc: 0.8654\n",
      "Epoch 291/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3106 - acc: 0.8667\n",
      "Epoch 292/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3112 - acc: 0.8648\n",
      "Epoch 293/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3104 - acc: 0.8642\n",
      "Epoch 294/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3108 - acc: 0.8648\n",
      "Epoch 295/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3112 - acc: 0.8648\n",
      "Epoch 296/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3109 - acc: 0.8654\n",
      "Epoch 297/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3108 - acc: 0.8673\n",
      "Epoch 298/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3109 - acc: 0.8654\n",
      "Epoch 299/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3105 - acc: 0.8667\n",
      "Epoch 300/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3108 - acc: 0.8648\n",
      "Epoch 301/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3105 - acc: 0.8648\n",
      "Epoch 302/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3107 - acc: 0.8661\n",
      "Epoch 303/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3106 - acc: 0.8673\n",
      "Epoch 304/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3106 - acc: 0.8673\n",
      "Epoch 305/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3104 - acc: 0.8654\n",
      "Epoch 306/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3105 - acc: 0.8667\n",
      "Epoch 307/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3106 - acc: 0.8661\n",
      "Epoch 308/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3106 - acc: 0.8648\n",
      "Epoch 309/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3104 - acc: 0.8661\n",
      "Epoch 310/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3102 - acc: 0.8679\n",
      "Epoch 311/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3101 - acc: 0.8667\n",
      "Epoch 312/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3105 - acc: 0.8661\n",
      "Epoch 313/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3102 - acc: 0.8642\n",
      "Epoch 314/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3104 - acc: 0.8654\n",
      "Epoch 315/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3104 - acc: 0.8667\n",
      "Epoch 316/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3103 - acc: 0.8679\n",
      "Epoch 317/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3105 - acc: 0.8661\n",
      "Epoch 318/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3099 - acc: 0.8673\n",
      "Epoch 319/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3104 - acc: 0.8654\n",
      "Epoch 320/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3102 - acc: 0.8667\n",
      "Epoch 321/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3104 - acc: 0.8636\n",
      "Epoch 322/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3099 - acc: 0.8667\n",
      "Epoch 323/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3099 - acc: 0.8654\n",
      "Epoch 324/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3099 - acc: 0.8654\n",
      "Epoch 325/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3101 - acc: 0.8642\n",
      "Epoch 326/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3103 - acc: 0.8654\n",
      "Epoch 327/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3101 - acc: 0.8654\n",
      "Epoch 328/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3102 - acc: 0.8630\n",
      "Epoch 329/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3101 - acc: 0.8661\n",
      "Epoch 330/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3102 - acc: 0.8648\n",
      "Epoch 331/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3098 - acc: 0.8667\n",
      "Epoch 332/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3099 - acc: 0.8642\n",
      "Epoch 333/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3100 - acc: 0.8661\n",
      "Epoch 334/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3102 - acc: 0.8612\n",
      "Epoch 335/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3101 - acc: 0.8624\n",
      "Epoch 336/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3099 - acc: 0.8667\n",
      "Epoch 337/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3097 - acc: 0.8642\n",
      "Epoch 338/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3100 - acc: 0.8648\n",
      "Epoch 339/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3097 - acc: 0.8661\n",
      "Epoch 340/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3096 - acc: 0.8642\n",
      "Epoch 341/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3100 - acc: 0.8636\n",
      "Epoch 342/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3095 - acc: 0.8654\n",
      "Epoch 343/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3096 - acc: 0.8654\n",
      "Epoch 344/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3097 - acc: 0.8654\n",
      "Epoch 345/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3096 - acc: 0.8624\n",
      "Epoch 346/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3098 - acc: 0.8636\n",
      "Epoch 347/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3096 - acc: 0.8648\n",
      "Epoch 348/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3094 - acc: 0.8654\n",
      "Epoch 349/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3096 - acc: 0.8654\n",
      "Epoch 350/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3094 - acc: 0.8654\n",
      "Epoch 351/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3099 - acc: 0.8630\n",
      "Epoch 352/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3093 - acc: 0.8667\n",
      "Epoch 353/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3096 - acc: 0.8642\n",
      "Epoch 354/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3096 - acc: 0.8636\n",
      "Epoch 355/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3096 - acc: 0.8648\n",
      "Epoch 356/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3095 - acc: 0.8636\n",
      "Epoch 357/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3093 - acc: 0.8630\n",
      "Epoch 358/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3095 - acc: 0.8642\n",
      "Epoch 359/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3095 - acc: 0.8642\n",
      "Epoch 360/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3093 - acc: 0.8636\n",
      "Epoch 361/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3095 - acc: 0.8642\n",
      "Epoch 362/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3090 - acc: 0.8648\n",
      "Epoch 363/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3096 - acc: 0.8642\n",
      "Epoch 364/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3097 - acc: 0.8642\n",
      "Epoch 365/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3092 - acc: 0.8630\n",
      "Epoch 366/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3100 - acc: 0.8636\n",
      "Epoch 367/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3092 - acc: 0.8648\n",
      "Epoch 368/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3092 - acc: 0.8630\n",
      "Epoch 369/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3092 - acc: 0.8648\n",
      "Epoch 370/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3090 - acc: 0.8642\n",
      "Epoch 371/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3094 - acc: 0.8642\n",
      "Epoch 372/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3096 - acc: 0.8642\n",
      "Epoch 373/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3092 - acc: 0.8661\n",
      "Epoch 374/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3092 - acc: 0.8654\n",
      "Epoch 375/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3092 - acc: 0.8654\n",
      "Epoch 376/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3091 - acc: 0.8667\n",
      "Epoch 377/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3089 - acc: 0.8661\n",
      "Epoch 378/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3094 - acc: 0.8624\n",
      "Epoch 379/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3089 - acc: 0.8642\n",
      "Epoch 380/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3089 - acc: 0.8642\n",
      "Epoch 381/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3091 - acc: 0.8642\n",
      "Epoch 382/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3091 - acc: 0.8636\n",
      "Epoch 383/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3090 - acc: 0.8630\n",
      "Epoch 384/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3091 - acc: 0.8642\n",
      "Epoch 385/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3090 - acc: 0.8624\n",
      "Epoch 386/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3088 - acc: 0.8654\n",
      "Epoch 387/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3092 - acc: 0.8636\n",
      "Epoch 388/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3087 - acc: 0.8636\n",
      "Epoch 389/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3090 - acc: 0.8642\n",
      "Epoch 390/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3088 - acc: 0.8654\n",
      "Epoch 391/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3089 - acc: 0.8654\n",
      "Epoch 392/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3091 - acc: 0.8636\n",
      "Epoch 393/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3088 - acc: 0.8636\n",
      "Epoch 394/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3089 - acc: 0.8654\n",
      "Epoch 395/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3089 - acc: 0.8630\n",
      "Epoch 396/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3087 - acc: 0.8636\n",
      "Epoch 397/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3087 - acc: 0.8630\n",
      "Epoch 398/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3085 - acc: 0.8636\n",
      "Epoch 399/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3089 - acc: 0.8636\n",
      "Epoch 400/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3088 - acc: 0.8642\n",
      "Epoch 401/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3091 - acc: 0.8642\n",
      "Epoch 402/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3086 - acc: 0.8648\n",
      "Epoch 403/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3089 - acc: 0.8630\n",
      "Epoch 404/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3088 - acc: 0.8642\n",
      "Epoch 405/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3087 - acc: 0.8654\n",
      "Epoch 406/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3088 - acc: 0.8630\n",
      "Epoch 407/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3090 - acc: 0.8642\n",
      "Epoch 408/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3085 - acc: 0.8636\n",
      "Epoch 409/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3090 - acc: 0.8624\n",
      "Epoch 410/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3085 - acc: 0.8636\n",
      "Epoch 411/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3085 - acc: 0.8648\n",
      "Epoch 412/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3087 - acc: 0.8642\n",
      "Epoch 413/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3086 - acc: 0.8624\n",
      "Epoch 414/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3086 - acc: 0.8648\n",
      "Epoch 415/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3086 - acc: 0.8648\n",
      "Epoch 416/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3087 - acc: 0.8642\n",
      "Epoch 417/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3085 - acc: 0.8642\n",
      "Epoch 418/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3089 - acc: 0.8612\n",
      "Epoch 419/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3083 - acc: 0.8648\n",
      "Epoch 420/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3085 - acc: 0.8630\n",
      "Epoch 421/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3086 - acc: 0.8618\n",
      "Epoch 422/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3086 - acc: 0.8630\n",
      "Epoch 423/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3089 - acc: 0.8636\n",
      "Epoch 424/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3088 - acc: 0.8630\n",
      "Epoch 425/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3087 - acc: 0.8648\n",
      "Epoch 426/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3086 - acc: 0.8654\n",
      "Epoch 427/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3084 - acc: 0.8661\n",
      "Epoch 428/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3082 - acc: 0.8642\n",
      "Epoch 429/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3083 - acc: 0.8648\n",
      "Epoch 430/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3086 - acc: 0.8642\n",
      "Epoch 431/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3081 - acc: 0.8648\n",
      "Epoch 432/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3085 - acc: 0.8648\n",
      "Epoch 433/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3082 - acc: 0.8636\n",
      "Epoch 434/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3086 - acc: 0.8648\n",
      "Epoch 435/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3081 - acc: 0.8636\n",
      "Epoch 436/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3082 - acc: 0.8630\n",
      "Epoch 437/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3082 - acc: 0.8648\n",
      "Epoch 438/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3083 - acc: 0.8642\n",
      "Epoch 439/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3085 - acc: 0.8648\n",
      "Epoch 440/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3084 - acc: 0.8654\n",
      "Epoch 441/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3084 - acc: 0.8618\n",
      "Epoch 442/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3083 - acc: 0.8636\n",
      "Epoch 443/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3082 - acc: 0.8636\n",
      "Epoch 444/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3084 - acc: 0.8667\n",
      "Epoch 445/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3082 - acc: 0.8642\n",
      "Epoch 446/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3080 - acc: 0.8636\n",
      "Epoch 447/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3081 - acc: 0.8642\n",
      "Epoch 448/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3082 - acc: 0.8654\n",
      "Epoch 449/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3082 - acc: 0.8630\n",
      "Epoch 450/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3080 - acc: 0.8612\n",
      "Epoch 451/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3081 - acc: 0.8642\n",
      "Epoch 452/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3083 - acc: 0.8648\n",
      "Epoch 453/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3081 - acc: 0.8642\n",
      "Epoch 454/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3081 - acc: 0.8630\n",
      "Epoch 455/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3083 - acc: 0.8624\n",
      "Epoch 456/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3078 - acc: 0.8642\n",
      "Epoch 457/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3084 - acc: 0.8636\n",
      "Epoch 458/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3085 - acc: 0.8642\n",
      "Epoch 459/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3080 - acc: 0.8630\n",
      "Epoch 460/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3079 - acc: 0.8630\n",
      "Epoch 461/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3087 - acc: 0.8630\n",
      "Epoch 462/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3079 - acc: 0.8636\n",
      "Epoch 463/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3078 - acc: 0.8636\n",
      "Epoch 464/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3081 - acc: 0.8624\n",
      "Epoch 465/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3082 - acc: 0.8618\n",
      "Epoch 466/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3081 - acc: 0.8630\n",
      "Epoch 467/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3078 - acc: 0.8661\n",
      "Epoch 468/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3081 - acc: 0.8624\n",
      "Epoch 469/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3077 - acc: 0.8618\n",
      "Epoch 470/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3080 - acc: 0.8642\n",
      "Epoch 471/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3079 - acc: 0.8630\n",
      "Epoch 472/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3080 - acc: 0.8618\n",
      "Epoch 473/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3076 - acc: 0.8661\n",
      "Epoch 474/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3077 - acc: 0.8624\n",
      "Epoch 475/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3081 - acc: 0.8630\n",
      "Epoch 476/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3080 - acc: 0.8612\n",
      "Epoch 477/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3077 - acc: 0.8630\n",
      "Epoch 478/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3079 - acc: 0.8630\n",
      "Epoch 479/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3077 - acc: 0.8642\n",
      "Epoch 480/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3079 - acc: 0.8636\n",
      "Epoch 481/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3079 - acc: 0.8624\n",
      "Epoch 482/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3078 - acc: 0.8630\n",
      "Epoch 483/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3078 - acc: 0.8630\n",
      "Epoch 484/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3076 - acc: 0.8624\n",
      "Epoch 485/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3077 - acc: 0.8654\n",
      "Epoch 486/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3078 - acc: 0.8630\n",
      "Epoch 487/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3077 - acc: 0.8648\n",
      "Epoch 488/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3074 - acc: 0.8624\n",
      "Epoch 489/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3078 - acc: 0.8642\n",
      "Epoch 490/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3075 - acc: 0.8618\n",
      "Epoch 491/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3074 - acc: 0.8636\n",
      "Epoch 492/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3076 - acc: 0.8630\n",
      "Epoch 493/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3078 - acc: 0.8624\n",
      "Epoch 494/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3080 - acc: 0.8648\n",
      "Epoch 495/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3075 - acc: 0.8624\n",
      "Epoch 496/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3076 - acc: 0.8630\n",
      "Epoch 497/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3079 - acc: 0.8636\n",
      "Epoch 498/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3075 - acc: 0.8618\n",
      "Epoch 499/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3077 - acc: 0.8630\n",
      "Epoch 500/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3077 - acc: 0.8642\n",
      "Epoch 501/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3080 - acc: 0.8630\n",
      "Epoch 502/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3076 - acc: 0.8630\n",
      "Epoch 503/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3073 - acc: 0.8630\n",
      "Epoch 504/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3074 - acc: 0.8630\n",
      "Epoch 505/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3076 - acc: 0.8642\n",
      "Epoch 506/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3077 - acc: 0.8636\n",
      "Epoch 507/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3076 - acc: 0.8612\n",
      "Epoch 508/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3074 - acc: 0.8636\n",
      "Epoch 509/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3075 - acc: 0.8630\n",
      "Epoch 510/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3075 - acc: 0.8661\n",
      "Epoch 511/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3076 - acc: 0.8642\n",
      "Epoch 512/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3076 - acc: 0.8654\n",
      "Epoch 513/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3073 - acc: 0.8648\n",
      "Epoch 514/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3073 - acc: 0.8661\n",
      "Epoch 515/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3074 - acc: 0.8636\n",
      "Epoch 516/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3072 - acc: 0.8642\n",
      "Epoch 517/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3075 - acc: 0.8648\n",
      "Epoch 518/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3075 - acc: 0.8642\n",
      "Epoch 519/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3074 - acc: 0.8630\n",
      "Epoch 520/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3077 - acc: 0.8630\n",
      "Epoch 521/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3073 - acc: 0.8636\n",
      "Epoch 522/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3074 - acc: 0.8648\n",
      "Epoch 523/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3072 - acc: 0.8630\n",
      "Epoch 524/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3074 - acc: 0.8599\n",
      "Epoch 525/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3076 - acc: 0.8661\n",
      "Epoch 526/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3074 - acc: 0.8636\n",
      "Epoch 527/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3079 - acc: 0.8624\n",
      "Epoch 528/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3075 - acc: 0.8636\n",
      "Epoch 529/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3072 - acc: 0.8661\n",
      "Epoch 530/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3072 - acc: 0.8654\n",
      "Epoch 531/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3070 - acc: 0.8606\n",
      "Epoch 532/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3074 - acc: 0.8642\n",
      "Epoch 533/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3074 - acc: 0.8654\n",
      "Epoch 534/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3075 - acc: 0.8624\n",
      "Epoch 535/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3070 - acc: 0.8661\n",
      "Epoch 536/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3073 - acc: 0.8648\n",
      "Epoch 537/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3071 - acc: 0.8636\n",
      "Epoch 538/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3070 - acc: 0.8642\n",
      "Epoch 539/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3073 - acc: 0.8630\n",
      "Epoch 540/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3070 - acc: 0.8642\n",
      "Epoch 541/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3073 - acc: 0.8636\n",
      "Epoch 542/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3071 - acc: 0.8630\n",
      "Epoch 543/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3071 - acc: 0.8624\n",
      "Epoch 544/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3072 - acc: 0.8636\n",
      "Epoch 545/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3069 - acc: 0.8642\n",
      "Epoch 546/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3070 - acc: 0.8648\n",
      "Epoch 547/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3073 - acc: 0.8648\n",
      "Epoch 548/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3074 - acc: 0.8642\n",
      "Epoch 549/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3070 - acc: 0.8661\n",
      "Epoch 550/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3070 - acc: 0.8654\n",
      "Epoch 551/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3073 - acc: 0.8630\n",
      "Epoch 552/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3069 - acc: 0.8654\n",
      "Epoch 553/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3071 - acc: 0.8654\n",
      "Epoch 554/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3072 - acc: 0.8661\n",
      "Epoch 555/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3072 - acc: 0.8630\n",
      "Epoch 556/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3068 - acc: 0.8624\n",
      "Epoch 557/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3071 - acc: 0.8673\n",
      "Epoch 558/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3072 - acc: 0.8654\n",
      "Epoch 559/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3072 - acc: 0.8654\n",
      "Epoch 560/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3071 - acc: 0.8636\n",
      "Epoch 561/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3070 - acc: 0.8661\n",
      "Epoch 562/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3067 - acc: 0.8648\n",
      "Epoch 563/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3071 - acc: 0.8673\n",
      "Epoch 564/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3069 - acc: 0.8636\n",
      "Epoch 565/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3072 - acc: 0.8648\n",
      "Epoch 566/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3070 - acc: 0.8642\n",
      "Epoch 567/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3069 - acc: 0.8667\n",
      "Epoch 568/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3069 - acc: 0.8648\n",
      "Epoch 569/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3070 - acc: 0.8630\n",
      "Epoch 570/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3068 - acc: 0.8642\n",
      "Epoch 571/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3068 - acc: 0.8661\n",
      "Epoch 572/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3068 - acc: 0.8661\n",
      "Epoch 573/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3069 - acc: 0.8654\n",
      "Epoch 574/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3068 - acc: 0.8648\n",
      "Epoch 575/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3068 - acc: 0.8654\n",
      "Epoch 576/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3069 - acc: 0.8648\n",
      "Epoch 577/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3071 - acc: 0.8642\n",
      "Epoch 578/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3068 - acc: 0.8654\n",
      "Epoch 579/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3067 - acc: 0.8654\n",
      "Epoch 580/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3069 - acc: 0.8642\n",
      "Epoch 581/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3067 - acc: 0.8654\n",
      "Epoch 582/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3067 - acc: 0.8648\n",
      "Epoch 583/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3072 - acc: 0.8648\n",
      "Epoch 584/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3067 - acc: 0.8648\n",
      "Epoch 585/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3068 - acc: 0.8648\n",
      "Epoch 586/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3072 - acc: 0.8648\n",
      "Epoch 587/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3066 - acc: 0.8648\n",
      "Epoch 588/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3070 - acc: 0.8636\n",
      "Epoch 589/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3068 - acc: 0.8642\n",
      "Epoch 590/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3072 - acc: 0.8661\n",
      "Epoch 591/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3067 - acc: 0.8648\n",
      "Epoch 592/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3064 - acc: 0.8661\n",
      "Epoch 593/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3068 - acc: 0.8648\n",
      "Epoch 594/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3068 - acc: 0.8654\n",
      "Epoch 595/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3070 - acc: 0.8630\n",
      "Epoch 596/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3068 - acc: 0.8642\n",
      "Epoch 597/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3074 - acc: 0.8618\n",
      "Epoch 598/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3067 - acc: 0.8642\n",
      "Epoch 599/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3066 - acc: 0.8636\n",
      "Epoch 600/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3070 - acc: 0.8624\n",
      "Epoch 601/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3068 - acc: 0.8642\n",
      "Epoch 602/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3066 - acc: 0.8648\n",
      "Epoch 603/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3066 - acc: 0.8648\n",
      "Epoch 604/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3068 - acc: 0.8667\n",
      "Epoch 605/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3066 - acc: 0.8654\n",
      "Epoch 606/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3066 - acc: 0.8636\n",
      "Epoch 607/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3069 - acc: 0.8642\n",
      "Epoch 608/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3065 - acc: 0.8642\n",
      "Epoch 609/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3067 - acc: 0.8654\n",
      "Epoch 610/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3063 - acc: 0.8642\n",
      "Epoch 611/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3065 - acc: 0.8654\n",
      "Epoch 612/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3066 - acc: 0.8642\n",
      "Epoch 613/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 614/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3066 - acc: 0.8661\n",
      "Epoch 615/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3065 - acc: 0.8667\n",
      "Epoch 616/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3065 - acc: 0.8661\n",
      "Epoch 617/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3065 - acc: 0.8636\n",
      "Epoch 618/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3066 - acc: 0.8654\n",
      "Epoch 619/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3064 - acc: 0.8636\n",
      "Epoch 620/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3064 - acc: 0.8630\n",
      "Epoch 621/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3065 - acc: 0.8661\n",
      "Epoch 622/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 623/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3063 - acc: 0.8642\n",
      "Epoch 624/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3069 - acc: 0.8648\n",
      "Epoch 625/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3065 - acc: 0.8618\n",
      "Epoch 626/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3065 - acc: 0.8630\n",
      "Epoch 627/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3069 - acc: 0.8642\n",
      "Epoch 628/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3066 - acc: 0.8654\n",
      "Epoch 629/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3067 - acc: 0.8642\n",
      "Epoch 630/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3062 - acc: 0.8661\n",
      "Epoch 631/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3063 - acc: 0.8661\n",
      "Epoch 632/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3063 - acc: 0.8648\n",
      "Epoch 633/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3064 - acc: 0.8673\n",
      "Epoch 634/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3065 - acc: 0.8654\n",
      "Epoch 635/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3065 - acc: 0.8667\n",
      "Epoch 636/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3064 - acc: 0.8624\n",
      "Epoch 637/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3061 - acc: 0.8673\n",
      "Epoch 638/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3063 - acc: 0.8654\n",
      "Epoch 639/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3063 - acc: 0.8661\n",
      "Epoch 640/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 641/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3063 - acc: 0.8654\n",
      "Epoch 642/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3064 - acc: 0.8661\n",
      "Epoch 643/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3062 - acc: 0.8654\n",
      "Epoch 644/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3065 - acc: 0.8642\n",
      "Epoch 645/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3065 - acc: 0.8673\n",
      "Epoch 646/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3064 - acc: 0.8642\n",
      "Epoch 647/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3064 - acc: 0.8667\n",
      "Epoch 648/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3068 - acc: 0.8642\n",
      "Epoch 649/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3063 - acc: 0.8636\n",
      "Epoch 650/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3064 - acc: 0.8661\n",
      "Epoch 651/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3065 - acc: 0.8654\n",
      "Epoch 652/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3063 - acc: 0.8636\n",
      "Epoch 653/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3067 - acc: 0.8654\n",
      "Epoch 654/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3062 - acc: 0.8648\n",
      "Epoch 655/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3061 - acc: 0.8642\n",
      "Epoch 656/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3061 - acc: 0.8654\n",
      "Epoch 657/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3062 - acc: 0.8648\n",
      "Epoch 658/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 659/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3061 - acc: 0.8667\n",
      "Epoch 660/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 661/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3066 - acc: 0.8654\n",
      "Epoch 662/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3061 - acc: 0.8648\n",
      "Epoch 663/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3066 - acc: 0.8648\n",
      "Epoch 664/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3061 - acc: 0.8667\n",
      "Epoch 665/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3063 - acc: 0.8667\n",
      "Epoch 666/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3062 - acc: 0.8648\n",
      "Epoch 667/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3060 - acc: 0.8673\n",
      "Epoch 668/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3061 - acc: 0.8642\n",
      "Epoch 669/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3062 - acc: 0.8661\n",
      "Epoch 670/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3061 - acc: 0.8673\n",
      "Epoch 671/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3061 - acc: 0.8667\n",
      "Epoch 672/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3060 - acc: 0.8654\n",
      "Epoch 673/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3062 - acc: 0.8636\n",
      "Epoch 674/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3061 - acc: 0.8636\n",
      "Epoch 675/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3063 - acc: 0.8648\n",
      "Epoch 676/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3075 - acc: 0.8654\n",
      "Epoch 677/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3060 - acc: 0.8648\n",
      "Epoch 678/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3061 - acc: 0.8648\n",
      "Epoch 679/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3062 - acc: 0.8654\n",
      "Epoch 680/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3063 - acc: 0.8661\n",
      "Epoch 681/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3061 - acc: 0.8636\n",
      "Epoch 682/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3064 - acc: 0.8661\n",
      "Epoch 683/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3061 - acc: 0.8661\n",
      "Epoch 684/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3059 - acc: 0.8679\n",
      "Epoch 685/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3062 - acc: 0.8654\n",
      "Epoch 686/4000\n",
      "1635/1635 [==============================] - 0s 104us/step - loss: 0.3063 - acc: 0.8648\n",
      "Epoch 687/4000\n",
      "1635/1635 [==============================] - 0s 109us/step - loss: 0.3062 - acc: 0.8654\n",
      "Epoch 688/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3059 - acc: 0.8667\n",
      "Epoch 689/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3060 - acc: 0.8648\n",
      "Epoch 690/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3061 - acc: 0.8654\n",
      "Epoch 691/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3060 - acc: 0.8661\n",
      "Epoch 692/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3061 - acc: 0.8642\n",
      "Epoch 693/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3061 - acc: 0.8642\n",
      "Epoch 694/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3061 - acc: 0.8648\n",
      "Epoch 695/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3059 - acc: 0.8667\n",
      "Epoch 696/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3064 - acc: 0.8661\n",
      "Epoch 697/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3061 - acc: 0.8654\n",
      "Epoch 698/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3062 - acc: 0.8667\n",
      "Epoch 699/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3059 - acc: 0.8654\n",
      "Epoch 700/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3063 - acc: 0.8648\n",
      "Epoch 701/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3058 - acc: 0.8667\n",
      "Epoch 702/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3058 - acc: 0.8648\n",
      "Epoch 703/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 704/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3062 - acc: 0.8661\n",
      "Epoch 705/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3066 - acc: 0.8642\n",
      "Epoch 706/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3060 - acc: 0.8648\n",
      "Epoch 707/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3059 - acc: 0.8642\n",
      "Epoch 708/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3060 - acc: 0.8673\n",
      "Epoch 709/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3064 - acc: 0.8654\n",
      "Epoch 710/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3063 - acc: 0.8648\n",
      "Epoch 711/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3059 - acc: 0.8661\n",
      "Epoch 712/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3060 - acc: 0.8654\n",
      "Epoch 713/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3060 - acc: 0.8648\n",
      "Epoch 714/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3061 - acc: 0.8667\n",
      "Epoch 715/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3058 - acc: 0.8661\n",
      "Epoch 716/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3056 - acc: 0.8654\n",
      "Epoch 717/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3062 - acc: 0.8667\n",
      "Epoch 718/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 719/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3060 - acc: 0.8661\n",
      "Epoch 720/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3060 - acc: 0.8673\n",
      "Epoch 721/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3059 - acc: 0.8642\n",
      "Epoch 722/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3058 - acc: 0.8661\n",
      "Epoch 723/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3058 - acc: 0.8654\n",
      "Epoch 724/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3056 - acc: 0.8667\n",
      "Epoch 725/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3060 - acc: 0.8673\n",
      "Epoch 726/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3060 - acc: 0.8661\n",
      "Epoch 727/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 728/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3059 - acc: 0.8661\n",
      "Epoch 729/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3060 - acc: 0.8679\n",
      "Epoch 730/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3058 - acc: 0.8673\n",
      "Epoch 731/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3059 - acc: 0.8661\n",
      "Epoch 732/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3057 - acc: 0.8654\n",
      "Epoch 733/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 734/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3057 - acc: 0.8679\n",
      "Epoch 735/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3061 - acc: 0.8667\n",
      "Epoch 736/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3058 - acc: 0.8654\n",
      "Epoch 737/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3058 - acc: 0.8667\n",
      "Epoch 738/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3057 - acc: 0.8654\n",
      "Epoch 739/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3061 - acc: 0.8654\n",
      "Epoch 740/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3060 - acc: 0.8667\n",
      "Epoch 741/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3057 - acc: 0.8654\n",
      "Epoch 742/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3061 - acc: 0.8636\n",
      "Epoch 743/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3059 - acc: 0.8636\n",
      "Epoch 744/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3055 - acc: 0.8642\n",
      "Epoch 745/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3058 - acc: 0.8673\n",
      "Epoch 746/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 747/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3058 - acc: 0.8654\n",
      "Epoch 748/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 749/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3058 - acc: 0.8673\n",
      "Epoch 750/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3058 - acc: 0.8661\n",
      "Epoch 751/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3058 - acc: 0.8667\n",
      "Epoch 752/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 753/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 754/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3056 - acc: 0.8661\n",
      "Epoch 755/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3058 - acc: 0.8679\n",
      "Epoch 756/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3056 - acc: 0.8667\n",
      "Epoch 757/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 758/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3056 - acc: 0.8654\n",
      "Epoch 759/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3059 - acc: 0.8654\n",
      "Epoch 760/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3057 - acc: 0.8654\n",
      "Epoch 761/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3056 - acc: 0.8661\n",
      "Epoch 762/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3057 - acc: 0.8673\n",
      "Epoch 763/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 764/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3058 - acc: 0.8661\n",
      "Epoch 765/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3058 - acc: 0.8673\n",
      "Epoch 766/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3058 - acc: 0.8654\n",
      "Epoch 767/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 768/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 769/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 770/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 771/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3056 - acc: 0.8648\n",
      "Epoch 772/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8636\n",
      "Epoch 773/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3055 - acc: 0.8648\n",
      "Epoch 774/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 775/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3059 - acc: 0.8648\n",
      "Epoch 776/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3057 - acc: 0.8685\n",
      "Epoch 777/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3056 - acc: 0.8636\n",
      "Epoch 778/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 779/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3056 - acc: 0.8667\n",
      "Epoch 780/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3057 - acc: 0.8636\n",
      "Epoch 781/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8642\n",
      "Epoch 782/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 783/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3056 - acc: 0.8654\n",
      "Epoch 784/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3055 - acc: 0.8667\n",
      "Epoch 785/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 786/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3060 - acc: 0.8648\n",
      "Epoch 787/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 788/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 789/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8648\n",
      "Epoch 790/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3057 - acc: 0.8685\n",
      "Epoch 791/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3053 - acc: 0.8642\n",
      "Epoch 792/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3057 - acc: 0.8673\n",
      "Epoch 793/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3057 - acc: 0.8648\n",
      "Epoch 794/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 795/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3057 - acc: 0.8648\n",
      "Epoch 796/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 797/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 798/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3056 - acc: 0.8648\n",
      "Epoch 799/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3056 - acc: 0.8667\n",
      "Epoch 800/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 801/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8648\n",
      "Epoch 802/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 803/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3054 - acc: 0.8654\n",
      "Epoch 804/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3056 - acc: 0.8648\n",
      "Epoch 805/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 806/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 807/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 808/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3057 - acc: 0.8654\n",
      "Epoch 809/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8654\n",
      "Epoch 810/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3056 - acc: 0.8648\n",
      "Epoch 811/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 812/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 813/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3056 - acc: 0.8661\n",
      "Epoch 814/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 815/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3052 - acc: 0.8679\n",
      "Epoch 816/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 817/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 818/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3056 - acc: 0.8661\n",
      "Epoch 819/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8648\n",
      "Epoch 820/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3055 - acc: 0.8691\n",
      "Epoch 821/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 822/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3053 - acc: 0.8673\n",
      "Epoch 823/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3057 - acc: 0.8661\n",
      "Epoch 824/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 825/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 826/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3057 - acc: 0.8648\n",
      "Epoch 827/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3055 - acc: 0.8661\n",
      "Epoch 828/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8673\n",
      "Epoch 829/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8673\n",
      "Epoch 830/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 831/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3054 - acc: 0.8673\n",
      "Epoch 832/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 833/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3057 - acc: 0.8667\n",
      "Epoch 834/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 835/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3054 - acc: 0.8685\n",
      "Epoch 836/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3056 - acc: 0.8648\n",
      "Epoch 837/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8648\n",
      "Epoch 838/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 839/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 840/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3055 - acc: 0.8642\n",
      "Epoch 841/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 842/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 843/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3055 - acc: 0.8648\n",
      "Epoch 844/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 845/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3054 - acc: 0.8679\n",
      "Epoch 846/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 847/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3054 - acc: 0.8679\n",
      "Epoch 848/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3054 - acc: 0.8691\n",
      "Epoch 849/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 850/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3060 - acc: 0.8673\n",
      "Epoch 851/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3053 - acc: 0.8691\n",
      "Epoch 852/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8654\n",
      "Epoch 853/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3055 - acc: 0.8667\n",
      "Epoch 854/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3053 - acc: 0.8667\n",
      "Epoch 855/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 856/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 857/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3056 - acc: 0.8667\n",
      "Epoch 858/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3053 - acc: 0.8642\n",
      "Epoch 859/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8648\n",
      "Epoch 860/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8679\n",
      "Epoch 861/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3053 - acc: 0.8667\n",
      "Epoch 862/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 863/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3053 - acc: 0.8667\n",
      "Epoch 864/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3053 - acc: 0.8679\n",
      "Epoch 865/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 866/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3054 - acc: 0.8691\n",
      "Epoch 867/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 868/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3053 - acc: 0.8679\n",
      "Epoch 869/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 870/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3053 - acc: 0.8673\n",
      "Epoch 871/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3056 - acc: 0.8661\n",
      "Epoch 872/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 873/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 874/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 875/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 876/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8685\n",
      "Epoch 877/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3055 - acc: 0.8642\n",
      "Epoch 878/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3053 - acc: 0.8673\n",
      "Epoch 879/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 880/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8648\n",
      "Epoch 881/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 882/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8654\n",
      "Epoch 883/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3052 - acc: 0.8679\n",
      "Epoch 884/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 885/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 886/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3053 - acc: 0.8642\n",
      "Epoch 887/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 888/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 889/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 890/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 891/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3053 - acc: 0.8661\n",
      "Epoch 892/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 893/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3051 - acc: 0.8685\n",
      "Epoch 894/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 895/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 896/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 897/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 898/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 899/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 900/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3050 - acc: 0.8679\n",
      "Epoch 901/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 902/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8685\n",
      "Epoch 903/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 904/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 905/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3053 - acc: 0.8661\n",
      "Epoch 906/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3053 - acc: 0.8673\n",
      "Epoch 907/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8685\n",
      "Epoch 908/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 909/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 910/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 911/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 912/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3053 - acc: 0.8661\n",
      "Epoch 913/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3050 - acc: 0.8673\n",
      "Epoch 914/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 915/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3055 - acc: 0.8654\n",
      "Epoch 916/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3053 - acc: 0.8648\n",
      "Epoch 917/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3050 - acc: 0.8673\n",
      "Epoch 918/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 919/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3052 - acc: 0.8685\n",
      "Epoch 920/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 921/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 922/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3055 - acc: 0.8673\n",
      "Epoch 923/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 924/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3050 - acc: 0.8673\n",
      "Epoch 925/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8679\n",
      "Epoch 926/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 927/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 928/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3051 - acc: 0.8691\n",
      "Epoch 929/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8691\n",
      "Epoch 930/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 931/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 932/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 933/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 934/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 935/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 936/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3053 - acc: 0.8648\n",
      "Epoch 937/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3053 - acc: 0.8636\n",
      "Epoch 938/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 939/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 940/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 941/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 942/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 943/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 944/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 945/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 946/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 947/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 948/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 949/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 950/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 951/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 952/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3050 - acc: 0.8679\n",
      "Epoch 953/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3048 - acc: 0.8673\n",
      "Epoch 954/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 955/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 956/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 957/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3050 - acc: 0.8673\n",
      "Epoch 958/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 959/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3050 - acc: 0.8636\n",
      "Epoch 960/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8703\n",
      "Epoch 961/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 962/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 963/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 964/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 965/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3051 - acc: 0.8679\n",
      "Epoch 966/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3050 - acc: 0.8679\n",
      "Epoch 967/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 968/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3054 - acc: 0.8667\n",
      "Epoch 969/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 970/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 971/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 972/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 973/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 974/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 975/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 976/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 977/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 978/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 979/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 980/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 981/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 982/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 983/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3052 - acc: 0.8679\n",
      "Epoch 984/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 985/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 986/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 987/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 988/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3054 - acc: 0.8642\n",
      "Epoch 989/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 990/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.8661\n",
      "Epoch 991/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3051 - acc: 0.8636\n",
      "Epoch 992/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 993/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 994/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3051 - acc: 0.8685\n",
      "Epoch 995/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 996/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3049 - acc: 0.8679\n",
      "Epoch 997/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3048 - acc: 0.8679\n",
      "Epoch 998/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 999/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 1000/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1001/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1002/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 1003/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3049 - acc: 0.8630\n",
      "Epoch 1004/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1005/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 1006/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1007/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 1008/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1009/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1010/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3053 - acc: 0.8654\n",
      "Epoch 1011/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1012/4000\n",
      "1635/1635 [==============================] - 0s 105us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 1013/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 1014/4000\n",
      "1635/1635 [==============================] - 0s 104us/step - loss: 0.3050 - acc: 0.8673\n",
      "Epoch 1015/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1016/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3051 - acc: 0.8679\n",
      "Epoch 1017/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1018/4000\n",
      "1635/1635 [==============================] - 0s 102us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1019/4000\n",
      "1635/1635 [==============================] - 0s 105us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1020/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3048 - acc: 0.8673\n",
      "Epoch 1021/4000\n",
      "1635/1635 [==============================] - 0s 99us/step - loss: 0.3051 - acc: 0.8636\n",
      "Epoch 1022/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3048 - acc: 0.8667\n",
      "Epoch 1023/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 1024/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3048 - acc: 0.8673\n",
      "Epoch 1025/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 1026/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 1027/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1028/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1029/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 1030/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8679\n",
      "Epoch 1031/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3051 - acc: 0.8667\n",
      "Epoch 1032/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1033/4000\n",
      "1635/1635 [==============================] - 0s 102us/step - loss: 0.3051 - acc: 0.8648\n",
      "Epoch 1034/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 1035/4000\n",
      "1635/1635 [==============================] - 0s 101us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1036/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1037/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1038/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3048 - acc: 0.8636\n",
      "Epoch 1039/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1040/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1041/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1042/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8636\n",
      "Epoch 1043/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 1044/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1045/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1046/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1047/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3051 - acc: 0.8636\n",
      "Epoch 1048/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1049/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 1050/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1051/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3052 - acc: 0.8667\n",
      "Epoch 1052/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 1053/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1054/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1055/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3052 - acc: 0.8654\n",
      "Epoch 1056/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1057/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8636\n",
      "Epoch 1058/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8630\n",
      "Epoch 1059/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1060/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8642\n",
      "Epoch 1061/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3053 - acc: 0.8642\n",
      "Epoch 1062/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8679\n",
      "Epoch 1063/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1064/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8636\n",
      "Epoch 1065/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8685\n",
      "Epoch 1066/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8636\n",
      "Epoch 1067/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1068/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1069/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1070/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1071/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1072/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3053 - acc: 0.8648\n",
      "Epoch 1073/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1074/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1075/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1076/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1077/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1078/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1079/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 1080/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3052 - acc: 0.8648\n",
      "Epoch 1081/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1082/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1083/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1084/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8642\n",
      "Epoch 1085/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3051 - acc: 0.8654\n",
      "Epoch 1086/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1087/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3052 - acc: 0.8661\n",
      "Epoch 1088/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1089/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1090/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 1091/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1092/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1093/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3051 - acc: 0.8630\n",
      "Epoch 1094/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3051 - acc: 0.8648\n",
      "Epoch 1095/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1096/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3046 - acc: 0.8679\n",
      "Epoch 1097/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3049 - acc: 0.8642\n",
      "Epoch 1098/4000\n",
      "1635/1635 [==============================] - 0s 99us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1099/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1100/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1101/4000\n",
      "1635/1635 [==============================] - 0s 104us/step - loss: 0.3049 - acc: 0.8673\n",
      "Epoch 1102/4000\n",
      "1635/1635 [==============================] - 0s 103us/step - loss: 0.3051 - acc: 0.8636\n",
      "Epoch 1103/4000\n",
      "1635/1635 [==============================] - 0s 114us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1104/4000\n",
      "1635/1635 [==============================] - 0s 108us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1105/4000\n",
      "1635/1635 [==============================] - 0s 105us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1106/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1107/4000\n",
      "1635/1635 [==============================] - 0s 102us/step - loss: 0.3052 - acc: 0.8673\n",
      "Epoch 1108/4000\n",
      "1635/1635 [==============================] - 0s 101us/step - loss: 0.3048 - acc: 0.8667\n",
      "Epoch 1109/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3045 - acc: 0.8636\n",
      "Epoch 1110/4000\n",
      "1635/1635 [==============================] - 0s 102us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1111/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1112/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3049 - acc: 0.8636\n",
      "Epoch 1113/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3049 - acc: 0.8624\n",
      "Epoch 1114/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3050 - acc: 0.8648\n",
      "Epoch 1115/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1116/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1117/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1118/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1119/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1120/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1121/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1122/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1123/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1124/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1125/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1126/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1127/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3047 - acc: 0.8636\n",
      "Epoch 1128/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1129/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1130/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1131/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1132/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1133/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3051 - acc: 0.8673\n",
      "Epoch 1134/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8636\n",
      "Epoch 1135/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1136/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1137/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8673\n",
      "Epoch 1138/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1139/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1140/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8667\n",
      "Epoch 1141/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1142/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1143/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3049 - acc: 0.8636\n",
      "Epoch 1144/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3049 - acc: 0.8679\n",
      "Epoch 1145/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1146/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1147/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1148/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1149/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8642\n",
      "Epoch 1150/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3046 - acc: 0.8679\n",
      "Epoch 1151/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1152/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1153/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1154/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1155/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3049 - acc: 0.8673\n",
      "Epoch 1156/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1157/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1158/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1159/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1160/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1161/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1162/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1163/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1164/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1165/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1166/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1167/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1168/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1169/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1170/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1171/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1172/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1173/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1174/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1175/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3045 - acc: 0.8624\n",
      "Epoch 1176/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1177/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1178/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1179/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1180/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8685\n",
      "Epoch 1181/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8630\n",
      "Epoch 1182/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3049 - acc: 0.8642\n",
      "Epoch 1183/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1184/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1185/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1186/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1187/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1188/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1189/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8630\n",
      "Epoch 1190/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1191/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3052 - acc: 0.8642\n",
      "Epoch 1192/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8636\n",
      "Epoch 1193/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1194/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3050 - acc: 0.8685\n",
      "Epoch 1195/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1196/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1197/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1198/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1199/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1200/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1201/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1202/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1203/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1204/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1205/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1206/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1207/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3050 - acc: 0.8654\n",
      "Epoch 1208/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1209/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1210/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1211/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1212/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1213/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1214/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1215/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3048 - acc: 0.8661\n",
      "Epoch 1216/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1217/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1218/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1219/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1220/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1221/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1222/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1223/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1224/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1225/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1226/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1227/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1228/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3051 - acc: 0.8661\n",
      "Epoch 1229/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 1230/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1231/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1232/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1233/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1234/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1235/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3049 - acc: 0.8654\n",
      "Epoch 1236/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1237/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1238/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1239/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8673\n",
      "Epoch 1240/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1241/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1242/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1243/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8673\n",
      "Epoch 1244/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1245/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1246/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1247/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1248/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1249/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3049 - acc: 0.8648\n",
      "Epoch 1250/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1251/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8673\n",
      "Epoch 1252/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1253/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1254/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1255/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1256/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1257/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1258/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1259/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1260/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1261/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1262/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3050 - acc: 0.8661\n",
      "Epoch 1263/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8630\n",
      "Epoch 1264/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1265/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1266/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1267/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1268/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1269/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1270/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1271/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8630\n",
      "Epoch 1272/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1273/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1274/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3049 - acc: 0.8685\n",
      "Epoch 1275/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1276/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1277/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1278/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1279/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8679\n",
      "Epoch 1280/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1281/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1282/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1283/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1284/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1285/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1286/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1287/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1288/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1289/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8624\n",
      "Epoch 1290/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3047 - acc: 0.8673\n",
      "Epoch 1291/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1292/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1293/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1294/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1295/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1296/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1297/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1298/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1299/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8679\n",
      "Epoch 1300/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1301/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1302/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3048 - acc: 0.8667\n",
      "Epoch 1303/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1304/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1305/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1306/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1307/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1308/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1309/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1310/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1311/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1312/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1313/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1314/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1315/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1316/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1317/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8636\n",
      "Epoch 1318/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1319/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3049 - acc: 0.8642\n",
      "Epoch 1320/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1321/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1322/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1323/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1324/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1325/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1326/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1327/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1328/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1329/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1330/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1331/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8636\n",
      "Epoch 1332/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1333/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1334/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8624\n",
      "Epoch 1335/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1336/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1337/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1338/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1339/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1340/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1341/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8673\n",
      "Epoch 1342/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8630\n",
      "Epoch 1343/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1344/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1345/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3050 - acc: 0.8642\n",
      "Epoch 1346/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1347/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1348/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1349/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1350/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1351/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1352/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1353/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1354/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1355/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1356/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8661\n",
      "Epoch 1357/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1358/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1359/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8636\n",
      "Epoch 1360/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1361/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1362/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1363/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1364/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1365/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3052 - acc: 0.8630\n",
      "Epoch 1366/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1367/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1368/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1369/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1370/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1371/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1372/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1373/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1374/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1375/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1376/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1377/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1378/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1379/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1380/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1381/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1382/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1383/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1384/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1385/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3047 - acc: 0.8636\n",
      "Epoch 1386/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1387/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1388/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1389/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1390/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1391/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1392/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1393/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1394/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1395/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1396/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1397/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1398/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1399/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1400/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1401/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1402/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1403/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1404/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1405/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8630\n",
      "Epoch 1406/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1407/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1408/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1409/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1410/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1411/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1412/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1413/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1414/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1415/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1416/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1417/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1418/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1419/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8630\n",
      "Epoch 1420/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1421/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1422/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1423/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1424/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1425/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1426/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1427/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1428/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1429/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1430/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1431/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1432/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1433/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1434/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1435/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1436/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1437/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1438/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1439/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1440/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1441/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1442/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8642\n",
      "Epoch 1443/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1444/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1445/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8667\n",
      "Epoch 1446/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1447/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1448/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1449/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1450/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8630\n",
      "Epoch 1451/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3049 - acc: 0.8661\n",
      "Epoch 1452/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8630\n",
      "Epoch 1453/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8648\n",
      "Epoch 1454/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8636\n",
      "Epoch 1455/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1456/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1457/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8636\n",
      "Epoch 1458/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1459/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1460/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1461/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1462/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1463/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1464/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1465/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1466/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1467/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1468/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1469/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1470/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1471/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1472/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1473/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1474/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1475/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1476/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1477/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1478/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1479/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1480/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1481/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1482/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1483/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1484/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1485/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1486/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1487/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1488/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1489/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1490/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1491/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1492/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8673\n",
      "Epoch 1493/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1494/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1495/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1496/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1497/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1498/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1499/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1500/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8636\n",
      "Epoch 1501/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1502/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1503/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1504/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1505/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1506/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1507/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1508/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1509/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1510/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1511/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8636\n",
      "Epoch 1512/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8685\n",
      "Epoch 1513/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1514/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8685\n",
      "Epoch 1515/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1516/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1517/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1518/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1519/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1520/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8636\n",
      "Epoch 1521/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1522/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8636\n",
      "Epoch 1523/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1524/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8654\n",
      "Epoch 1525/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1526/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8679\n",
      "Epoch 1527/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1528/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1529/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1530/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1531/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1532/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1533/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1534/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1535/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1536/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1537/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1538/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1539/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1540/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1541/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1542/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1543/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1544/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1545/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1546/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1547/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1548/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1549/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1550/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8636\n",
      "Epoch 1551/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1552/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1553/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1554/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1555/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1556/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1557/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1558/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1559/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1560/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1561/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1562/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1563/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1564/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1565/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1566/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1567/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1568/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1569/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1570/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1571/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1572/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1573/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1574/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1575/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1576/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3042 - acc: 0.8636\n",
      "Epoch 1577/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1578/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1579/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1580/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1581/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1582/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1583/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1584/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1585/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1586/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1587/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1588/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1589/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1590/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1591/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1592/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1593/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1594/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1595/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1596/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1597/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1598/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1599/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8673\n",
      "Epoch 1600/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1601/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1602/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1603/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1604/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1605/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1606/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1607/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8679\n",
      "Epoch 1608/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1609/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1610/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1611/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1612/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1613/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1614/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1615/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1616/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1617/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1618/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1619/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1620/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1621/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1622/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1623/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8630\n",
      "Epoch 1624/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3047 - acc: 0.8654\n",
      "Epoch 1625/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1626/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1627/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1628/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8691\n",
      "Epoch 1629/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1630/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1631/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1632/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1633/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 1634/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1635/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1636/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1637/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1638/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1639/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1640/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1641/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1642/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1643/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3047 - acc: 0.8642\n",
      "Epoch 1644/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1645/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1646/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1647/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1648/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1649/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1650/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1651/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1652/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1653/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1654/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1655/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1656/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1657/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1658/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1659/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1660/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3048 - acc: 0.8642\n",
      "Epoch 1661/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1662/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1663/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1664/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8685\n",
      "Epoch 1665/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8630\n",
      "Epoch 1666/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1667/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1668/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1669/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1670/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1671/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1672/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1673/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1674/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1675/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1676/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1677/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1678/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1679/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8636\n",
      "Epoch 1680/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1681/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1682/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3045 - acc: 0.8648\n",
      "Epoch 1683/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1684/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1685/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1686/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1687/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1688/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3044 - acc: 0.8624\n",
      "Epoch 1689/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1690/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8661\n",
      "Epoch 1691/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1692/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1693/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1694/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1695/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1696/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1697/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1698/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1699/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1700/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1701/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1702/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1703/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8630\n",
      "Epoch 1704/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1705/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1706/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1707/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1708/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1709/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1710/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 1711/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1712/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8654\n",
      "Epoch 1713/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1714/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1715/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1716/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1717/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1718/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1719/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8636\n",
      "Epoch 1720/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1721/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8679\n",
      "Epoch 1722/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1723/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1724/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1725/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1726/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1727/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1728/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8654\n",
      "Epoch 1729/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1730/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1731/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1732/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8618\n",
      "Epoch 1733/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1734/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8648\n",
      "Epoch 1735/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1736/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1737/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1738/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1739/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1740/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1741/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1742/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1743/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1744/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1745/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1746/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1747/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3045 - acc: 0.8636\n",
      "Epoch 1748/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1749/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1750/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1751/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1752/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1753/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1754/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1755/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8685\n",
      "Epoch 1756/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1757/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1758/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1759/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8679\n",
      "Epoch 1760/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1761/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1762/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1763/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1764/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1765/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1766/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1767/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1768/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1769/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1770/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1771/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1772/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1773/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1774/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1775/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1776/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1777/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1778/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1779/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1780/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 1781/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1782/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1783/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1784/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1785/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8642\n",
      "Epoch 1786/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1787/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1788/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1789/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1790/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1791/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1792/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1793/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1794/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1795/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1796/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1797/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1798/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1799/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1800/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1801/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1802/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1803/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1804/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1805/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1806/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1807/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1808/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1809/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1810/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1811/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3048 - acc: 0.8642\n",
      "Epoch 1812/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1813/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1814/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1815/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1816/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1817/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1818/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3046 - acc: 0.8648\n",
      "Epoch 1819/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1820/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1821/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1822/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1823/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1824/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1825/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1826/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1827/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1828/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1829/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1830/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1831/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 1832/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8630\n",
      "Epoch 1833/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1834/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1835/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 1836/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1837/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 1838/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3047 - acc: 0.8636\n",
      "Epoch 1839/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1840/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8636\n",
      "Epoch 1841/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1842/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8642\n",
      "Epoch 1843/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1844/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1845/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 1846/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1847/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1848/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1849/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1850/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1851/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1852/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1853/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1854/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8679\n",
      "Epoch 1855/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1856/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1857/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1858/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3042 - acc: 0.8630\n",
      "Epoch 1859/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1860/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1861/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1862/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1863/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 1864/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1865/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1866/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1867/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1868/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1869/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1870/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 1871/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1872/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1873/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1874/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1875/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1876/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 1877/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1878/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1879/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3045 - acc: 0.8642\n",
      "Epoch 1880/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1881/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 1882/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1883/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1884/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1885/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 1886/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1887/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1888/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3046 - acc: 0.8630\n",
      "Epoch 1889/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1890/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1891/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3047 - acc: 0.8624\n",
      "Epoch 1892/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1893/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1894/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1895/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1896/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1897/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1898/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1899/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1900/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 1901/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1902/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1903/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1904/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1905/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1906/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 1907/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1908/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1909/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1910/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1911/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 1912/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8679\n",
      "Epoch 1913/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1914/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3046 - acc: 0.8667\n",
      "Epoch 1915/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 1916/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1917/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1918/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3043 - acc: 0.8685\n",
      "Epoch 1919/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1920/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1921/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8636\n",
      "Epoch 1922/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1923/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1924/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8685\n",
      "Epoch 1925/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1926/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1927/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 1928/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1929/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1930/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1931/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1932/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 1933/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1934/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1935/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1936/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 1937/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1938/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8636\n",
      "Epoch 1939/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3039 - acc: 0.8648\n",
      "Epoch 1940/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 1941/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1942/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1943/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3047 - acc: 0.8648\n",
      "Epoch 1944/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1945/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 1946/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1947/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1948/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1949/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 1950/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1951/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 1952/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3045 - acc: 0.8667\n",
      "Epoch 1953/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3042 - acc: 0.8636\n",
      "Epoch 1954/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1955/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1956/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1957/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1958/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1959/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 1960/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1961/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1962/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1963/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 1964/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1965/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1966/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1967/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 1968/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3043 - acc: 0.8673\n",
      "Epoch 1969/4000\n",
      "1635/1635 [==============================] - 0s 97us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1970/4000\n",
      "1635/1635 [==============================] - 0s 101us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 1971/4000\n",
      "1635/1635 [==============================] - 0s 104us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1972/4000\n",
      "1635/1635 [==============================] - 0s 107us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1973/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 1974/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1975/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 1976/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1977/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 1978/4000\n",
      "1635/1635 [==============================] - 0s 98us/step - loss: 0.3046 - acc: 0.8661\n",
      "Epoch 1979/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 1980/4000\n",
      "1635/1635 [==============================] - 0s 96us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 1981/4000\n",
      "1635/1635 [==============================] - 0s 99us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1982/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 1983/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1984/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1985/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 1986/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 1987/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 1988/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1989/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1990/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 1991/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 1992/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 1993/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 1994/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8648\n",
      "Epoch 1995/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 1996/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 1997/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 1998/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 1999/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 2000/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2001/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3041 - acc: 0.8642\n",
      "Epoch 2002/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 2003/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2004/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2005/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2006/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8630\n",
      "Epoch 2007/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2008/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2009/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 2010/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8648\n",
      "Epoch 2011/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 2012/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 2013/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2014/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3039 - acc: 0.8654\n",
      "Epoch 2015/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3039 - acc: 0.8654\n",
      "Epoch 2016/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 2017/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2018/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 2019/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 2020/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2021/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8648\n",
      "Epoch 2022/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2023/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2024/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 2025/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2026/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2027/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2028/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 2029/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2030/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 2031/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2032/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2033/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2034/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 2035/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2036/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2037/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 2038/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8697\n",
      "Epoch 2039/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2040/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2041/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2042/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2043/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2044/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2045/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2046/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2047/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2048/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2049/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2050/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2051/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2052/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 2053/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3045 - acc: 0.8685\n",
      "Epoch 2054/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2055/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2056/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2057/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2058/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8648\n",
      "Epoch 2059/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2060/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 2061/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8685\n",
      "Epoch 2062/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 2063/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2064/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 2065/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2066/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2067/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2068/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2069/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2070/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2071/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2072/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2073/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2074/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2075/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3038 - acc: 0.8673\n",
      "Epoch 2076/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2077/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 2078/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8636\n",
      "Epoch 2079/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 2080/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2081/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2082/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2083/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2084/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2085/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2086/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 2087/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 2088/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3043 - acc: 0.8679\n",
      "Epoch 2089/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8654\n",
      "Epoch 2090/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2091/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2092/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2093/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2094/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2095/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2096/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2097/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3040 - acc: 0.8697\n",
      "Epoch 2098/4000\n",
      "1635/1635 [==============================] - 0s 101us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2099/4000\n",
      "1635/1635 [==============================] - 0s 103us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2100/4000\n",
      "1635/1635 [==============================] - 0s 101us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 2101/4000\n",
      "1635/1635 [==============================] - 0s 95us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2102/4000\n",
      "1635/1635 [==============================] - 0s 102us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2103/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2104/4000\n",
      "1635/1635 [==============================] - 0s 100us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2105/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3042 - acc: 0.8685\n",
      "Epoch 2106/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2107/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2108/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8642\n",
      "Epoch 2109/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 2110/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8685\n",
      "Epoch 2111/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2112/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 2113/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3038 - acc: 0.8703\n",
      "Epoch 2114/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2115/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8697\n",
      "Epoch 2116/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 2117/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2118/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2119/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8691\n",
      "Epoch 2120/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2121/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2122/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2123/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2124/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2125/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2126/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2127/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2128/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 2129/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2130/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8654\n",
      "Epoch 2131/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2132/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2133/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8691\n",
      "Epoch 2134/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2135/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2136/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2137/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 2138/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2139/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2140/4000\n",
      "1635/1635 [==============================] - 0s 80us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2141/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2142/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2143/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2144/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 2145/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3042 - acc: 0.8685\n",
      "Epoch 2146/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2147/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2148/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2149/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2150/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 2151/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2152/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2153/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2154/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8685\n",
      "Epoch 2155/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8679\n",
      "Epoch 2156/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 2157/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2158/4000\n",
      "1635/1635 [==============================] - 0s 94us/step - loss: 0.3041 - acc: 0.8679\n",
      "Epoch 2159/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2160/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2161/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2162/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 2163/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 2164/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2165/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 2166/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2167/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2168/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2169/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2170/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2171/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2172/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2173/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2174/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2175/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2176/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2177/4000\n",
      "1635/1635 [==============================] - 0s 91us/step - loss: 0.3044 - acc: 0.8661\n",
      "Epoch 2178/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2179/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2180/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3038 - acc: 0.8673\n",
      "Epoch 2181/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 2182/4000\n",
      "1635/1635 [==============================] - 0s 92us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 2183/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2184/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 2185/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2186/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2187/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 2188/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 2189/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 2190/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2191/4000\n",
      "1635/1635 [==============================] - 0s 99us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2192/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3038 - acc: 0.8685\n",
      "Epoch 2193/4000\n",
      "1635/1635 [==============================] - 0s 93us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2194/4000\n",
      "1635/1635 [==============================] - 0s 89us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 2195/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8673\n",
      "Epoch 2196/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 2197/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 2198/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2199/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3043 - acc: 0.8667\n",
      "Epoch 2200/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2201/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2202/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3046 - acc: 0.8654\n",
      "Epoch 2203/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8691\n",
      "Epoch 2204/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3043 - acc: 0.8661\n",
      "Epoch 2205/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2206/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2207/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3039 - acc: 0.8661\n",
      "Epoch 2208/4000\n",
      "1635/1635 [==============================] - 0s 90us/step - loss: 0.3042 - acc: 0.8654\n",
      "Epoch 2209/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2210/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2211/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3040 - acc: 0.8654\n",
      "Epoch 2212/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2213/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3038 - acc: 0.8648\n",
      "Epoch 2214/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2215/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3040 - acc: 0.8648\n",
      "Epoch 2216/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3042 - acc: 0.8667\n",
      "Epoch 2217/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2218/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3040 - acc: 0.8661\n",
      "Epoch 2219/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2220/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8685\n",
      "Epoch 2221/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3041 - acc: 0.8648\n",
      "Epoch 2222/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2223/4000\n",
      "1635/1635 [==============================] - 0s 87us/step - loss: 0.3042 - acc: 0.8661\n",
      "Epoch 2224/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8673\n",
      "Epoch 2225/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3044 - acc: 0.8618\n",
      "Epoch 2226/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2227/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2228/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3039 - acc: 0.8673\n",
      "Epoch 2229/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3042 - acc: 0.8673\n",
      "Epoch 2230/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3039 - acc: 0.8654\n",
      "Epoch 2231/4000\n",
      "1635/1635 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8673\n",
      "Epoch 2232/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3039 - acc: 0.8667\n",
      "Epoch 2233/4000\n",
      "1635/1635 [==============================] - 0s 83us/step - loss: 0.3044 - acc: 0.8667\n",
      "Epoch 2234/4000\n",
      "1635/1635 [==============================] - 0s 86us/step - loss: 0.3041 - acc: 0.8667\n",
      "Epoch 2235/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3042 - acc: 0.8642\n",
      "Epoch 2236/4000\n",
      "1635/1635 [==============================] - 0s 85us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2237/4000\n",
      "1635/1635 [==============================] - 0s 84us/step - loss: 0.3041 - acc: 0.8661\n",
      "Epoch 2238/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3043 - acc: 0.8642\n",
      "Epoch 2239/4000\n",
      "1635/1635 [==============================] - 0s 81us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2240/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3040 - acc: 0.8667\n",
      "Epoch 2241/4000\n",
      "1635/1635 [==============================] - 0s 82us/step - loss: 0.3038 - acc: 0.8667\n",
      "Epoch 2242/4000\n",
      "  16/1635 [..............................] - ETA: 0s - loss: 0.1154 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "# Importando o keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits_kfold = 2\n",
    "\n",
    "path_arquivos = 'Classificadores/Redes-neurais-MLP-2/'\n",
    "\n",
    "# datasets_treino = [train_data_2, train_data_b_2, train_data_1, train_data_b_1, train_data_3, train_data_b_3, train_data_4, train_data_b_4]\n",
    "# targets_treino = [train_target_2, train_target_b_2, train_target_1, train_target_b_1, train_target_3, train_target_b_3, train_target_4, train_target_b_4]\n",
    "\n",
    "datasets_treino = [train_data_2, train_data_b_2]\n",
    "targets_treino = [train_target_2, train_target_b_2]\n",
    "\n",
    "# Dicionário para saber a qual abordagem a iteração atual corresponde. Lembrando que, como existem\n",
    "# duas versões de dataset (balanceado e desbalanceado) para cada abordagem, e, ao todo, são 4 \n",
    "# abordagens, segue que a cada 2 iterações, a abordagem muda. Como começa pela abordagem 2 (em vez da 1), \n",
    "# as duas primeiras iterações referem-se à abordagem 2.\n",
    "\n",
    "abordagens_dict = {0: 2, 1: 2,\n",
    "                   2: 1, 3: 1,\n",
    "                   4: 3, 5: 3,\n",
    "                   6: 4, 7: 4}\n",
    "\n",
    "for aux, (train, target) in enumerate(zip(datasets_treino, targets_treino)):\n",
    "    \n",
    "    tb_train = pd.DataFrame(columns=['split'+str(i)+'_train_'+metrica for i in list(range(0,n_splits_kfold)) for metrica in metricas])\n",
    "    tb_val = pd.DataFrame(columns=['split'+str(i)+'_test_'+metrica for i in list(range(0,n_splits_kfold)) for metrica in metricas])\n",
    "    tb = pd.concat([tb_train, tb_val], axis=1)\n",
    "    \n",
    "    id_abordagem = abordagens_dict[aux]\n",
    "    \n",
    "    if aux % 2 == 0:\n",
    "        str_balanceamento = 'desbalanceado'\n",
    "    else:\n",
    "        str_balanceamento = 'balanceado'\n",
    "    \n",
    "    train_ann = pd.get_dummies(train).values\n",
    "    target_ann = target.replace(-1,0).values\n",
    "\n",
    "#     Criação de uma rede\n",
    "\n",
    "    param_range = list(map(int,np.logspace(start=1,stop=12,num=2,base=2))) # Número de neurônios por camada\n",
    "    \n",
    "    idx_linha = 0\n",
    "\n",
    "    for n_neuronios in param_range:\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(n_neuronios, input_shape=(train_ann.shape[1],), activation='sigmoid'))\n",
    "        # model.add(Dense(100, activation='sigmoid'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Problema de classificação binária,\n",
    "        model.compile(optimizer='NAdam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0,write_graph=True, write_images=True)\n",
    "\n",
    "        # Validação cruzada\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=n_splits_kfold,shuffle=True,random_state=0)\n",
    "\n",
    "        # Criação dos vetores que armazenam os resultados das métricas\n",
    "        \n",
    "        train_scores_acc = np.zeros(n_splits_kfold)\n",
    "        val_scores_acc = np.zeros(n_splits_kfold)\n",
    "        \n",
    "        train_scores_pre = np.zeros(n_splits_kfold)\n",
    "        val_scores_pre = np.zeros(n_splits_kfold)\n",
    "        \n",
    "        train_scores_rec = np.zeros(n_splits_kfold)\n",
    "        val_scores_rec = np.zeros(n_splits_kfold)\n",
    "\n",
    "        train_scores_f1 = np.zeros(n_splits_kfold)\n",
    "        val_scores_f1 = np.zeros(n_splits_kfold)\n",
    "\n",
    "        train_scores_roc = np.zeros(n_splits_kfold)\n",
    "        val_scores_roc = np.zeros(n_splits_kfold)\n",
    "\n",
    "        # Loop da validação cruzada\n",
    "        \n",
    "        n_rodada = 0\n",
    "        for idx_treino,idx_validacao in kfold.split(train_ann,target_ann):\n",
    "\n",
    "            # Treinamento da rede\n",
    "            model.fit(train_ann[idx_treino], target_ann[idx_treino], epochs=4000, batch_size=16, callbacks=[tbCallBack])\n",
    "\n",
    "            # Cálculo das probabilidades de cada classe para os registros\n",
    "            train_predictions_proba = model.predict(train_ann[idx_treino])\n",
    "            val_predictions_proba = model.predict(train_ann[idx_validacao])\n",
    "\n",
    "            # Definição das labels de cada registro, baseados nas probabilidades das classes para o registro em questão \n",
    "            train_predictions_labels = np.zeros(train_predictions_proba[:,0].shape[0])\n",
    "            for i in range(0,train_predictions_proba[:,0].shape[0]):\n",
    "                train_predictions_labels[i] = 1 if (train_predictions_proba[:,0][i] > 0.5) else 0\n",
    "\n",
    "            val_predictions_labels = np.zeros(val_predictions_proba[:,0].shape[0])\n",
    "            for i in range(0,val_predictions_proba[:,0].shape[0]):\n",
    "                val_predictions_labels[i] = 1 if (val_predictions_proba[:,0][i] > 0.5) else 0\n",
    "\n",
    "            # Cálculo das medidas\n",
    "            train_scores_acc[n_rodada] = accuracy_score(target_ann[idx_treino],train_predictions_labels)\n",
    "            val_scores_acc[n_rodada] = accuracy_score(target_ann[idx_validacao],val_predictions_labels)\n",
    "            \n",
    "            train_scores_pre[n_rodada] = precision_score(target_ann[idx_treino],train_predictions_labels)\n",
    "            val_scores_pre[n_rodada] = precision_score(target_ann[idx_validacao],val_predictions_labels)\n",
    "            \n",
    "            train_scores_rec[n_rodada] = recall_score(target_ann[idx_treino],train_predictions_labels)\n",
    "            val_scores_rec[n_rodada] = recall_score(target_ann[idx_validacao],val_predictions_labels)\n",
    "\n",
    "            train_scores_f1[n_rodada] = f1_score(target_ann[idx_treino],train_predictions_labels)\n",
    "            val_scores_f1[n_rodada] = f1_score(target_ann[idx_validacao],val_predictions_labels)\n",
    "\n",
    "            train_scores_roc[n_rodada] = roc_auc_score(target_ann[idx_treino],train_predictions_proba)\n",
    "            val_scores_roc[n_rodada] = roc_auc_score(target_ann[idx_validacao],val_predictions_proba)\n",
    "\n",
    "            n_rodada = n_rodada+1\n",
    "\n",
    "        # Montagem da tabela com os resultados de validação cruzada do treino da rede\n",
    "\n",
    "        metricas = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "        linha = gerarLinhaTabelaResultadosCVRedeNeural(metricas, \n",
    "                                                       n_splits_kfold,\n",
    "                                                       train_scores_acc,\n",
    "                                                       train_scores_pre,\n",
    "                                                       train_scores_rec,\n",
    "                                                       train_scores_f1,\n",
    "                                                       train_scores_roc,\n",
    "                                                       val_scores_acc,\n",
    "                                                       val_scores_pre,\n",
    "                                                       val_scores_rec,\n",
    "                                                       val_scores_f1,\n",
    "                                                       val_scores_roc)\n",
    "        display(linha)\n",
    "        tb.loc[idx_linha,:] = linha\n",
    "        idx_linha += 1\n",
    "    \n",
    "    tb['param_n_neuronios'] = param_range\n",
    "    joblib.dump(tb, path_arquivos+'mlp-one-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "#     display(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_train_accuracy</th>\n",
       "      <th>split0_train_f1</th>\n",
       "      <th>split0_train_roc_auc</th>\n",
       "      <th>split1_train_accuracy</th>\n",
       "      <th>split1_train_f1</th>\n",
       "      <th>split1_train_roc_auc</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51581</td>\n",
       "      <td>0.0613027</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.657188</td>\n",
       "      <td>0.743347</td>\n",
       "      <td>0.888538</td>\n",
       "      <td>0.516588</td>\n",
       "      <td>0.0642202</td>\n",
       "      <td>0.885648</td>\n",
       "      <td>0.658498</td>\n",
       "      <td>0.744379</td>\n",
       "      <td>0.897784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  split0_train_accuracy split0_train_f1 split0_train_roc_auc  \\\n",
       "0               0.51581       0.0613027             0.898571   \n",
       "\n",
       "  split1_train_accuracy split1_train_f1 split1_train_roc_auc  \\\n",
       "0              0.657188        0.743347             0.888538   \n",
       "\n",
       "  split0_test_accuracy split0_test_f1 split0_test_roc_auc  \\\n",
       "0             0.516588      0.0642202            0.885648   \n",
       "\n",
       "  split1_test_accuracy split1_test_f1 split1_test_roc_auc  \n",
       "0             0.658498       0.744379            0.897784  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5158102766798419, 0.06130268199233716, 0.8985711384336579,\n",
       "        0.6571879936808847, 0.7433471318746304, 0.8885379309140007,\n",
       "        0.5165876777251185, 0.06422018348623854, 0.8856479089767877,\n",
       "        0.658498023715415, 0.744378698224852, 0.8977843740723961]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gerarLinhaTabelaResultadosCVRedeNeural(metricas, \n",
    "                                           n_splits,\n",
    "                                           train_scores_acc, \n",
    "                                           train_scores_f1,\n",
    "                                           train_scores_roc,\n",
    "                                           val_scores_acc,\n",
    "                                           val_scores_f1,\n",
    "                                           val_scores_roc):\n",
    "\n",
    "    # Tabela com resultados de treino\n",
    "\n",
    "    tb_train = pd.DataFrame(columns=['split'+str(i)+'_train_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    idx_vetores = -1\n",
    "    for idx2,col in enumerate(tb_train.columns):\n",
    "        if idx2%3 == 0:\n",
    "            idx_vetores += 1\n",
    "            vetor = train_scores_acc\n",
    "        elif idx2%3 == 1:\n",
    "            vetor = train_scores_f1\n",
    "        elif idx2%3 == 2:\n",
    "            vetor = train_scores_roc\n",
    "\n",
    "        tb_train.loc[0,col] = vetor[idx_vetores]\n",
    "        \n",
    "#     display(tb_train)\n",
    "\n",
    "    # Tabela com resultados de validação\n",
    "\n",
    "    tb_val = pd.DataFrame(columns=['split'+str(i)+'_test_'+metrica for i in list(range(0,n_splits)) for metrica in metricas])\n",
    "\n",
    "    idx_vetores = -1\n",
    "    for idx2,col in enumerate(tb_val.columns):\n",
    "        if idx2%3 == 0:\n",
    "            idx_vetores += 1\n",
    "            vetor = val_scores_acc\n",
    "        elif idx2%3 == 1:\n",
    "            vetor = val_scores_f1\n",
    "        elif idx2%3 == 2:\n",
    "            vetor = val_scores_roc\n",
    "\n",
    "        tb_val.loc[0,col] = vetor[idx_vetores]\n",
    "\n",
    "    # Concatenação das duas tabelas\n",
    "\n",
    "    tb = pd.concat([tb_train, tb_val], axis=1)\n",
    "\n",
    "#     # Adicionando as colunas com os parâmetros\n",
    "\n",
    "#     tb['param_n_neuronios'] = param_range\n",
    "    \n",
    "    return tb, tb.values\n",
    "\n",
    "temp, linha = gerarLinhaTabelaResultadosCVRedeNeural(metricas, \n",
    "                                                       n_splits_kfold,\n",
    "                                                       train_scores_acc,\n",
    "                                                       train_scores_f1,\n",
    "                                                       train_scores_roc,\n",
    "                                                       val_scores_acc,\n",
    "                                                       val_scores_f1,\n",
    "                                                       val_scores_roc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
