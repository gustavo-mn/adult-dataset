{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvores de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos necessários para o processamento dos dados\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "\n",
    "# Módulos necessários para visualização dos dados\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando os módulos auxiliares\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Divisão de conjunto de treinamento e teste\n",
    "from sklearn.model_selection import cross_validate # Validação cruzada do modelo\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV # Busca pelos melhores hiperparâmetros\n",
    "from sklearn.externals import joblib # Necessário para salvar os modelos treinados em arquivos externos\n",
    "from imblearn.over_sampling import SMOTE # Balanceamento de classes\n",
    "\n",
    "# Métricas de avaliação\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "# Função auxiliar para plotar a matriz de confusão. \n",
    "# Retirada de: \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classe real')\n",
    "    plt.xlabel('Classe predita')\n",
    "    \n",
    "def gerar_dataset_balanceado(train_data, \n",
    "                             train_target, \n",
    "                             test_data, \n",
    "                             test_target):\n",
    "    \n",
    "    sm = SMOTE(random_state=0)\n",
    "    \n",
    "    train_data_b, train_target_b = sm.fit_sample(pd.get_dummies(train_data), train_target)\n",
    "\n",
    "    train_data_b = pd.DataFrame(train_data_b, columns=pd.get_dummies(train_data).columns)\n",
    "    train_data_b['earnings'] = train_target_b\n",
    "    train_data_b = train_data_b.sample(frac=1) # Embaralha os registros\n",
    "    \n",
    "    train_target_b = train_data_b['earnings']\n",
    "    train_data_b.drop(columns='earnings', inplace=True)\n",
    "    \n",
    "    \n",
    "    test_data_b, test_target_b = sm.fit_sample(pd.get_dummies(test_data), test_target)\n",
    "\n",
    "    test_data_b = pd.DataFrame(test_data_b, columns=pd.get_dummies(test_data).columns)\n",
    "    test_data_b['earnings'] = test_target_b\n",
    "    test_data_b = test_data_b.sample(frac=1) # Embaralha os registros\n",
    "    \n",
    "    test_target_b = test_data_b['earnings']\n",
    "    test_data_b.drop(columns='earnings', inplace=True)\n",
    "    \n",
    "    return train_data_b, train_target_b, test_data_b, test_target_b\n",
    "\n",
    "def exibir_resultados_finais(clf, \n",
    "                             test_data, \n",
    "                             test_target, \n",
    "                             id_abordagem, \n",
    "                             str_balanceamento, \n",
    "                             path_arquivos,\n",
    "                             tipo_classificador,\n",
    "                             fracao_dataset=0.1):\n",
    "    \n",
    "    # Classificando o conjunto de teste\n",
    "\n",
    "    predicoes = clf.predict(test_data)\n",
    "\n",
    "    # Salvando a árvore treinada graficamente\n",
    "\n",
    "    export_graphviz(clf, \n",
    "                    out_file=path_arquivos+tipo_classificador+'-final-abordagem-'+str(id_abordagem)+'-'+str_balanceamento+'-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "                    feature_names=test_data.columns,  \n",
    "                    class_names=['Less than or equal to', 'More than'],  \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "\n",
    "    # Avaliando o desempenho\n",
    "\n",
    "    # Matriz de confusão\n",
    "\n",
    "    cfs_mtx = confusion_matrix(test_target, predicoes)\n",
    "\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(cfs_mtx, \n",
    "                     xticklabels=['<=50K', '>50K'], \n",
    "                     yticklabels=['<=50K', '>50K'], \n",
    "                     annot=cfs_mtx,\n",
    "                     fmt='d',\n",
    "                     cbar=None)\n",
    "\n",
    "    ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "    ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "    ax.set_title('Matriz de Confusão')\n",
    "\n",
    "    # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "    plt.show()\n",
    "\n",
    "    acc = accuracy_score(test_target, predicoes)\n",
    "    pre = precision_score(test_target, predicoes)\n",
    "    rec = recall_score(test_target, predicoes)\n",
    "    roc_auc = roc_auc_score(test_target, predicoes)\n",
    "    prc_auc = average_precision_score(test_target, predicoes)\n",
    "\n",
    "    print('Acurácia: %.3f %%' % (acc*100))\n",
    "    print('Precisão: %.3f %%' % (pre*100))\n",
    "    print('Recall: %.3f %%' % (rec*100))\n",
    "    print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "    print('PRC AUC: %.3f %%' % (prc_auc*100))\n",
    "\n",
    "# ATENÇÃO!!! Escolher corretamente qual a fração do dataset que está sendo utilizada\n",
    "\n",
    "fracao_dataset = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os arquivos com os datasets pré-processados\n",
    "\n",
    "path_arquivos = 'Data/'\n",
    "\n",
    "data_pre_proc_1 = pd.read_csv(path_arquivos+'data-pre-proc-1.csv')\n",
    "data_pre_proc_2 = pd.read_csv(path_arquivos+'data-pre-proc-2.csv')\n",
    "data_pre_proc_3 = pd.read_csv(path_arquivos+'data-pre-proc-3.csv')\n",
    "data_pre_proc_4 = pd.read_csv(path_arquivos+'data-pre-proc-4.csv')\n",
    "\n",
    "# Descartando a primeira coluna, que é só identificador do registro\n",
    "\n",
    "data_pre_proc_1 = data_pre_proc_1.iloc[:,1::]\n",
    "data_pre_proc_2 = data_pre_proc_2.iloc[:,1::]\n",
    "data_pre_proc_3 = data_pre_proc_3.iloc[:,1::]\n",
    "data_pre_proc_4 = data_pre_proc_4.iloc[:,1::]\n",
    "\n",
    "# Separando o target e dividindo os conjuntos de treino e teste para cada dataset\n",
    "\n",
    "# Dataset 1\n",
    "\n",
    "target_1 = data_pre_proc_1['earnings']\n",
    "data_pre_proc_1.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_1, test_data_1, train_target_1, test_target_1 = train_test_split(\n",
    "    data_pre_proc_1, target_1, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_1, train_target_b_1, test_data_b_1, test_target_b_1 = gerar_dataset_balanceado(\n",
    "    train_data_1, train_target_1, test_data_1, test_target_1)\n",
    "\n",
    "# Dataset 2\n",
    "\n",
    "target_2 = data_pre_proc_2['earnings']\n",
    "data_pre_proc_2.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_2, test_data_2, train_target_2, test_target_2 = train_test_split(\n",
    "    data_pre_proc_2, target_2, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_2, train_target_b_2, test_data_b_2, test_target_b_2 = gerar_dataset_balanceado(\n",
    "    train_data_2, train_target_2, test_data_2, test_target_2)\n",
    "    \n",
    "# Dataset 3\n",
    "    \n",
    "target_3 = data_pre_proc_3['earnings']\n",
    "data_pre_proc_3.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_3, test_data_3, train_target_3, test_target_3 = train_test_split(\n",
    "    data_pre_proc_3, target_3, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_3, train_target_b_3, test_data_b_3, test_target_b_3 = gerar_dataset_balanceado(\n",
    "    train_data_3, train_target_3, test_data_3, test_target_3)\n",
    "    \n",
    "# Dataset 4    \n",
    "\n",
    "target_4 = data_pre_proc_4['earnings']\n",
    "data_pre_proc_4.drop(columns='earnings', inplace=True)\n",
    "\n",
    "train_data_4, test_data_4, train_target_4, test_target_4 = train_test_split(\n",
    "    data_pre_proc_4, target_4, test_size=0.33, random_state=0)\n",
    "\n",
    "train_data_b_4, train_target_b_4, test_data_b_4, test_target_b_4 = gerar_dataset_balanceado(\n",
    "    train_data_4, train_target_4, test_data_4, test_target_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando a distribuição dos targets em cada conjunto (treino e teste) de cada abordagem\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "temp_train = [train_target_1, train_target_2, train_target_3, train_target_4]\n",
    "temp_test = [test_target_1, test_target_2, test_target_3, test_target_4]\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    ax = temp_train[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_train[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Treino ' + str(i+1))\n",
    "#     plt.show()\n",
    "\n",
    "#     fig = plt.figure(figsize=(30,15))\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    ax = temp_test[i].value_counts().plot.bar()\n",
    "    for patch in ax.patches:\n",
    "#         ax.text(patch.get_x(), patch.get_height(), str(int(patch.get_height())),fontsize=20)\n",
    "        ax.text(patch.get_x(), patch.get_height(), \"{:.2f}%\".format((int(patch.get_height())/temp_test[i].shape[0]*100)),fontsize=20)\n",
    "    plt.title('Teste ' + str(i+1))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando módulos da árvore de decisão\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Árvore de decisão\n",
    "from sklearn.tree import export_graphviz # Utilitário para visualizar a árvore treinada\n",
    "\n",
    "# Definindo os parâmetros do modelo e possíveis valores\n",
    "\n",
    "max_max_depth_parameter = 102\n",
    "min_max_depth_parameter = 2\n",
    "\n",
    "param_grid = {'criterion': list(['gini', 'entropy']), \n",
    "              'max_depth': list(range(min_max_depth_parameter,max_max_depth_parameter+1))}\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None)\n",
    "\n",
    "# dt_desbalanceado = DecisionTreeClassifier(class_weight=None) # Não balanceando as classes\n",
    "# dt_balanceado = DecisionTreeClassifier(class_weight='balanced') # Balanceando as classes\n",
    "\n",
    "# Validação cruzada com cada conjunto de parâmetros\n",
    "\n",
    "clf = GridSearchCV(dt,param_grid,return_train_score=True,cv=10,\n",
    "                  scoring = ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], refit=False)\n",
    "\n",
    "# clf_desbalanceado = GridSearchCV(dt_desbalanceado,param_grid,return_train_score=True,cv=10, \n",
    "#                    scoring = ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], refit=False)\n",
    "\n",
    "# clf_balanceado = GridSearchCV(dt_balanceado,param_grid,return_train_score=True,cv=10, \n",
    "#                    scoring = ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], refit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para as árvores de decisão treinadas, foram considerados dois parâmetros: o critério de divisão ('gini' ou 'entropia') e o número máximo de níveis (profundidade) da árvore. Este último parâmetro serve para limitar que a árvore cresça indefinidamente e o problema de overfitting seja evitado (esse problema será discutido mais adiante). De certa forma, limitar o número máximo de níveis é uma espécie de esquema de \"pré-poda\" da árvore, em que o tratamento para evitar overfitting é feito durante a geração da árvore. Nos casos de \"pós-poda\" (não utilizados nessa implementação), a árvore primeiro é gerada, sem restrição de níveis, e, sem seguida, ramos vão sendo cortados segundo algum critério."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar somente se for necessário retreinar a árvore\n",
    "\n",
    "# Abordagem 1: Retirar os valores faltantes e manter outliers\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf.fit(pd.get_dummies(train_data_1), train_target_1) # Classes desbalanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "clf.fit(train_data_b_1, train_target_b_1) # Classes balanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "\n",
    "# clf_desbalanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "# clf_balanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "\n",
    "# Salvando os resultados da validação cruzada\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# joblib.dump(clf_desbalanceado, path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "# joblib.dump(clf_balanceado, path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, será feita uma breve análise do desempenho de diferentes árvores de decisão (obtidas com diferentes conjuntos de parâmetros), considerando o caso em que as classes estão não-balanceadas e balanceadas. O balanceamento é feito adotando pesos diferentes para cada classe. Aspectos, como overfitting, também serão analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_desbalanceado = joblib.load(path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_desbalanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se perceber que, tanto o critério de divisão de gini quanto o de entropia apresentam resultados semelhantes. Além disso, observa-se, nos gráficos, o efeito de overfitting. No começo, poucos níveis fazem com que a acurácia da árvore seja ruim. Existe um ponto \"ótimo\", no qual a acurácia atinge o máximo, e depois começa a decrescer novamente. No momento em que isso acontece, a árvore está sofrendo overfitting, ou seja, ela se sai muito bem no conjunto de treino, mas quando é usada para classificar exemplos fora do conjunto de treinamento, começa a errar mais.\n",
    "\n",
    "Outro fato interessante a se observar é que, a partir de um determinado número de níveis, a acurácia (e as outras métricas de recall, precisão e roc auc) começa a estabilizar. Isso ocorre, porque, embora o número máximo de níveis esteja aumentando, a árvore já esgotou todos os níveis possíveis (isto é, ela não cresce mais). Por isso, aumentar o número máximo de níveis, nesse caso, não influencia nos valores das métricas resultantes. O motivo de haver uma variação nos resultados da métrica conforme o número máximo de níveis aumenta é porque mais de uma árvore de decisão atende ao problema de classificação (não existe uma árvore única). Dessa forma, cada árvore gerada possui um erro e desvio-padrão associados, mas vemos que esses erros e desvios-padrão são próximos, mostrando que elas apresentam um desempenho semelhante. Portanto, nessa região em que os resultados das métricas estabilizam, o que está sendo observado, na realidade, é o efeito de várias árvores diferentes sendo treinadas (provavelmente com o mesmo número de níveis), e não uma influência do número máximo de níveis.\n",
    "\n",
    "Por conta do desbalanceamento entre as classes, a árvore tende a favorecer a classe mais frequente. Por consequência disso, ela erra muitos exemplos da classe menos frequente. Isso pode ser observado na métrica de recall, que é mais baixa do que a acurácia. Note, também, que a métrica de recall é menos afetada pelo overfitting nesse caso, ao contrário das outras. Isso decorre do desbalanceamento de classes. Quanto mais níveis, a tendência é que mais regras (pouco precisas) que classifiquem as como pertencentes à classe mais frequente sejam geradas. Como essas regras não devem dizer respeito à classe minoritária, elas não pioram ou melhoram o desempenho do classificador para tais instâncias dessa classe. Já para a classe majoritária, tais regras imprecisas farão com que o classificador erre mais suas classificações para tais amostras. Isso pode, por exemplo, ser concluído observando os resultados da métrica roc auc. A taxa de falso positivos, ou seja, de instâncias negativas classificadas como positivas, começa a crescer, diminuindo, assim, o valor dessa métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia', 'gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "    \n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_' + str(metrica[0])).transpose()\n",
    "        results_train_filtered = results_train.filter(regex='.*_train_' + str(metrica[0])).transpose()\n",
    "\n",
    "#         results_test_filtered = results_test_filtered.iloc[:, 0:int((results_test_filtered.shape[1]/2))]\n",
    "#         results_train_filtered = results_train_filtered.iloc[:, 0:int((results_train_filtered.shape[1]/2))]\n",
    "\n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "        results_train_filtered = results_train_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "        plt.plot(n_max_depths, results_test_filtered.mean(), label='Validação', color='green', lw=2)\n",
    "        plt.fill_between(n_max_depths, results_test_filtered.mean() - results_test_filtered.std(),\n",
    "                     results_test_filtered.mean() + results_test_filtered.std(), alpha=0.2, color='green', lw=2)\n",
    "\n",
    "        plt.plot(n_max_depths, results_train_filtered.mean(), label='Treino', color='blue', lw=2)\n",
    "        plt.fill_between(n_max_depths, results_train_filtered.mean() - results_train_filtered.std(),\n",
    "                     results_train_filtered.mean() + results_train_filtered.std(), alpha=0.2, color='blue', lw=2)\n",
    "        plt.title('Curvas de validação ('+ criterio + '): '+ metrica[1], fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.legend(loc='best', fontsize=30)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os gráficos anteriores são outra ilustração do problema de overfitting. Estão exibidos os resultados de treino e teste (validação) da acurácia do classificador em cada divisão da validação cruzada (em cada partição do k-fold, onde k = 10). Para a curva de treino, vemos que ela sempre é crescente, conforme o número de níveis aumenta. Cada vez mais, a árvore vai se especializando no conjunto de treino em questão, garantindo uma maior acurácia. Ao observarmos a curva de teste, no entanto, vemos que a partir de um determinado número de níveis (algo em torno de 10 a 15 níveis), o desempenho do classificador começa a piorar. Isso se dá por conta do overfitting. Note, também, que a partir de um determinado número de níveis, o erro de teste estabiliza. Isso é uma consequência de árvores diferentes (que alcançaram o máximo número de níveis para o dataset em questão) estarem sendo geradas. Como todas as árvores, nessa situação, já apresentam o mesmo número de níveis, aumentar o número máximo de níveis não altera o desempenho do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_desbalanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_desbalanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "joblib.dump(dt_final_desbalanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_desbalanceado = joblib.load(path_arquivos+'arvore-final-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_desbalanceado, \n",
    "                         test_data=pd.get_dummies(test_data_1), \n",
    "                         test_target=test_target_1, \n",
    "                         id_abordagem=1, \n",
    "                         str_balanceamento='desbalanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_desbalanceado.predict(pd.get_dummies(test_data_1))\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_desbalanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=pd.get_dummies(test_data_1).columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_1, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_1, predicoes)\n",
    "# pre = precision_score(test_target_1, predicoes)\n",
    "# rec = recall_score(test_target_1, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_1, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_1, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_balanceado = joblib.load(path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_balanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando as classes encontram-se balanceadas, por meio de pesos diferentes para cada amostra, observa-se que a acurácia máxima alcançada, dentre todos os classificadores treinados, é mais baixa do que no caso anterior (o mesmo vale para a precisão). Isso porque, agora, mais peso é dado às classes menos frequentes (uma classificação errada das classes minoritárias gera uma penalização maior ao modelo). Note que o recall, nesse caso, também aumentou. \n",
    "\n",
    "A métrica ROC AUC é invariante à questão de balanceamento/desbalanceamento de classes, porque a curva ROC (e, consequentemente, a área sob ela) depende de duas medidas que consideram a população total de uma única classe: taxa de verdadeiros positivos e taxa de falsos positivos. No caso, a taxa de verdadeiros positivos é calculada sobre a população da classe positiva, enquanto que a taxa de falsos negativos é calculada sobre a população da classe negativa. Com isso, como ambas as medidas não levam em conta a relação entre a quantidade de cada classe na população total, segue que o fato das classes estarem ou não balanceadas não altera o resultado da curva ROC.\n",
    "\n",
    "Dessa forma, uma métrica que traz mais informações sobre o desempenho do classificador em problemas desbalanceados é a área sob a curva de precision-recall (Precision-Recall Curve - PRC). Como a métrica de precisão leva em conta a proporção entre as classes, as curvas precisão-recall mudam de acordo com o balanceamento das classes. Em problemas desbalanceados, um bom classificador pode ser pensado como aquele que obtém um bom score de recall e precisão (isto é, ele consegue resgatar a maior parte dos registros da classe minoritária (recall alto) e, além disso, acerta a maior parte dos registros que classifica como sendo da classe minoritária (precisão alta)). Tendo isso em vista, como o problema em questão é desbalanceado, o classificador será escolhido com base no maior valor para a métrica PRC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia', 'gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "    \n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_' + str(metrica[0])).transpose()\n",
    "        results_train_filtered = results_train.filter(regex='.*_train_' + str(metrica[0])).transpose()\n",
    "\n",
    "#         results_test_filtered = results_test_filtered.iloc[:, 0:int((results_test_filtered.shape[1]/2))]\n",
    "#         results_train_filtered = results_train_filtered.iloc[:, 0:int((results_train_filtered.shape[1]/2))]\n",
    "\n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "        results_train_filtered = results_train_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "        plt.plot(n_max_depths, results_test_filtered.mean(), label='Validação', color='green', lw=2)\n",
    "        plt.fill_between(n_max_depths, results_test_filtered.mean() - results_test_filtered.std(),\n",
    "                     results_test_filtered.mean() + results_test_filtered.std(), alpha=0.2, color='green', lw=2)\n",
    "\n",
    "        plt.plot(n_max_depths, results_train_filtered.mean(), label='Treino', color='blue', lw=2)\n",
    "        plt.fill_between(n_max_depths, results_train_filtered.mean() - results_train_filtered.std(),\n",
    "                     results_train_filtered.mean() + results_train_filtered.std(), alpha=0.2, color='blue', lw=2)\n",
    "        plt.title('Curvas de validação ('+ criterio + '): '+ metrica[1], fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.legend(loc='best', fontsize=30)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_balanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_balanceado.fit(train_data_b_1, train_target_b_1)\n",
    "joblib.dump(dt_final_balanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_balanceado = joblib.load(path_arquivos+'arvore-final-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_balanceado, \n",
    "                         test_data=test_data_b_1, \n",
    "                         test_target=test_target_b_1, \n",
    "                         id_abordagem=1, \n",
    "                         str_balanceamento='balanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_balanceado.predict(test_data_b_1)\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_balanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=test_data_b_1.columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_b_1, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_b_1, predicoes)\n",
    "# pre = precision_score(test_target_b_1, predicoes)\n",
    "# rec = recall_score(test_target_b_1, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_b_1, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_b_1, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar somente se for necessário retreinar a árvore\n",
    "\n",
    "# Abordagem 2: Imputar os valores faltantes e manter outliers\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf.fit(pd.get_dummies(train_data_2), train_target_2) # Classes desbalanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-2-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "clf.fit(train_data_b_2, train_target_b_2) # Classes balanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-2-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "\n",
    "# clf_desbalanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "# clf_balanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "\n",
    "# Salvando os resultados da validação cruzada\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# joblib.dump(clf_desbalanceado, path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "# joblib.dump(clf_balanceado, path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_desbalanceado = joblib.load(path_arquivos+'arvores-abordagem-2-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_desbalanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_desbalanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_desbalanceado.fit(pd.get_dummies(train_data_2), train_target_2)\n",
    "joblib.dump(dt_final_desbalanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-2-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_desbalanceado = joblib.load(path_arquivos+'arvore-final-abordagem-2-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_desbalanceado, \n",
    "                         test_data=pd.get_dummies(test_data_2), \n",
    "                         test_target=test_target_2, \n",
    "                         id_abordagem=2, \n",
    "                         str_balanceamento='desbalanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_desbalanceado.predict(pd.get_dummies(test_data_2))\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_desbalanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-2-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=pd.get_dummies(test_data_2).columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_2, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_2, predicoes)\n",
    "# pre = precision_score(test_target_2, predicoes)\n",
    "# rec = recall_score(test_target_2, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_2, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_2, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_balanceado = joblib.load(path_arquivos+'arvores-abordagem-2-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_balanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme pode-se observar pelos gráficos plotados anteriormente, a imputação de dados pelo valor de moda das features não acarreta em uma melhora ou piora significativa no desempenho das árvores treinadas. No caso das classes desbalanceadas, os resultados com imputação são ligeiramente piores do que sem imputação. Já para as classes balanceadas, há uma leve melhora somente em árvores que sofrem com overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_balanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_balanceado.fit(train_data_b_2, train_target_b_2)\n",
    "joblib.dump(dt_final_balanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-2-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_balanceado = joblib.load(path_arquivos+'arvore-final-abordagem-2-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_balanceado, \n",
    "                         test_data=test_data_b_2, \n",
    "                         test_target=test_target_b_2, \n",
    "                         id_abordagem=2, \n",
    "                         str_balanceamento='balanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_balanceado.predict(test_data_b_2)\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_balanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-2-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=test_data_b_2.columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_b_2, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_b_2, predicoes)\n",
    "# pre = precision_score(test_target_b_2, predicoes)\n",
    "# rec = recall_score(test_target_b_2, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_b_2, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_b_2, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar somente se for necessário retreinar a árvore\n",
    "\n",
    "# Abordagem 3: Imputar os valores faltantes e retirar outliers\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf.fit(pd.get_dummies(train_data_3), train_target_3) # Classes desbalanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-3-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "clf.fit(train_data_b_3, train_target_b_3) # Classes balanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-3-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "\n",
    "# clf_desbalanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "# clf_balanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "\n",
    "# Salvando os resultados da validação cruzada\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# joblib.dump(clf_desbalanceado, path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "# joblib.dump(clf_balanceado, path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_desbalanceado = joblib.load(path_arquivos+'arvores-abordagem-3-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_desbalanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_desbalanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_desbalanceado.fit(pd.get_dummies(train_data_3), train_target_3)\n",
    "joblib.dump(dt_final_desbalanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-3-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_desbalanceado = joblib.load(path_arquivos+'arvore-final-abordagem-3-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_desbalanceado, \n",
    "                         test_data=pd.get_dummies(test_data_3), \n",
    "                         test_target=test_target_3, \n",
    "                         id_abordagem=3, \n",
    "                         str_balanceamento='desbalanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_desbalanceado.predict(pd.get_dummies(test_data_3))\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_desbalanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-3-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=pd.get_dummies(test_data_3).columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_3, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_3, predicoes)\n",
    "# pre = precision_score(test_target_3, predicoes)\n",
    "# rec = recall_score(test_target_3, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_3, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_3, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_balanceado = joblib.load(path_arquivos+'arvores-abordagem-3-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_balanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_balanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_balanceado.fit(train_data_b_3, train_target_b_3)\n",
    "joblib.dump(dt_final_balanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-3-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_balanceado = joblib.load(path_arquivos+'arvore-final-abordagem-3-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_balanceado, \n",
    "                         test_data=test_data_b_1, \n",
    "                         test_target=test_target_b_1, \n",
    "                         id_abordagem=3, \n",
    "                         str_balanceamento='balanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_balanceado.predict(test_data_b_3)\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_balanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-3-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=test_data_b_3.columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_b_3, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_b_3, predicoes)\n",
    "# pre = precision_score(test_target_b_3, predicoes)\n",
    "# rec = recall_score(test_target_b_3, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_b_3, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_b_3, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar somente se for necessário retreinar a árvore\n",
    "\n",
    "# Abordagem 4: Retirar os valores faltantes e retirar outliers\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf.fit(pd.get_dummies(train_data_4), train_target_4) # Classes desbalanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-4-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "clf.fit(train_data_b_4, train_target_b_4) # Classes balanceadas\n",
    "joblib.dump(clf, \n",
    "            path_arquivos+'arvores-abordagem-4-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando os resultados da validação cruzada\n",
    "\n",
    "\n",
    "# clf_desbalanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "# clf_balanceado.fit(pd.get_dummies(train_data_1), train_target_1)\n",
    "\n",
    "# Salvando os resultados da validação cruzada\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# joblib.dump(clf_desbalanceado, path_arquivos+'arvores-abordagem-1-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "# joblib.dump(clf_balanceado, path_arquivos+'arvores-abordagem-1-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_desbalanceado = joblib.load(path_arquivos+'arvores-abordagem-4-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_desbalanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_desbalanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_desbalanceado.fit(pd.get_dummies(train_data_4), train_target_4)\n",
    "joblib.dump(dt_final_desbalanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-4-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_desbalanceado = joblib.load(path_arquivos+'arvore-final-abordagem-4-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_desbalanceado, \n",
    "                         test_data=pd.get_dummies(test_data_4), \n",
    "                         test_target=test_target_4, \n",
    "                         id_abordagem=4, \n",
    "                         str_balanceamento='desbalanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_desbalanceado.predict(pd.get_dummies(test_data_4))\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_desbalanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-4-desbalanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=pd.get_dummies(test_data_4).columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_4, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_4, predicoes)\n",
    "# pre = precision_score(test_target_4, predicoes)\n",
    "# rec = recall_score(test_target_4, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_4, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_4, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "clf_balanceado = joblib.load(path_arquivos+'arvores-abordagem-4-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "results = pd.DataFrame(clf_balanceado.cv_results_)\n",
    "# results['param_criterion'].head()\n",
    "results.sort_values(by=['param_criterion','param_max_depth'], axis=0, inplace=True)\n",
    "# results['param_criterion'].head()\n",
    "results_test = results.loc[:, 'split0_test_accuracy':'split9_train_roc_auc']\n",
    "results_train = results_test.filter(regex=(\".*train.*\"))\n",
    "results_test.drop(columns=results_train.columns,inplace=True)\n",
    "\n",
    "# for col in results.columns:\n",
    "#     print(col)\n",
    "\n",
    "lista_metricas = [('accuracy', 'acurácias'), ('average_precision', 'PRC AUC'), ('f1', 'F1 score'), ('precision', 'precisões'), ('recall', 'recall'), ('roc_auc', 'ROC AUC')]\n",
    "\n",
    "# Plot das barras de erro\n",
    "\n",
    "n_max_depths = np.arange(min_max_depth_parameter,max_max_depth_parameter+1) \n",
    "\n",
    "for criterio in ['entropia','gini']:\n",
    "    \n",
    "    if criterio == 'entropia':\n",
    "        range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "    elif criterio == 'gini':\n",
    "        range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "    for metrica in lista_metricas:\n",
    "\n",
    "        results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "        results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "        fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "        plt.errorbar(n_max_depths, results_test_filtered.mean(), yerr=results_test_filtered.std(), fmt='o', lw=2)\n",
    "        plt.title('Barras de erro (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "        plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "        plt.xticks(fontsize=30, rotation=90)\n",
    "        plt.yticks(fontsize=30)\n",
    "        plt.show()\n",
    "\n",
    "# Boxplots\n",
    "\n",
    "# for criterio in ['entropia','gini']:\n",
    "    \n",
    "#     if criterio == 'entropia':\n",
    "#         range_cols = list(range(0,int(results_test.shape[0]/2)))\n",
    "#     elif criterio == 'gini':\n",
    "#         range_cols = list(range(int(results_test.shape[0]/2),results_test.shape[0]))\n",
    "\n",
    "#     for metrica in lista_metricas:\n",
    "\n",
    "#         results_test_filtered = results_test.filter(regex='.*_test_'+str(metrica[0])).transpose()\n",
    "        \n",
    "#         results_test_filtered = results_test_filtered.iloc[:, range_cols]\n",
    "\n",
    "#         fig = plt.figure(figsize=(30,15))\n",
    "        \n",
    "#         results_test_filtered.boxplot()\n",
    "        \n",
    "#         plt.title('Boxplot (' + criterio + '): ' + metrica[1], fontsize=30)\n",
    "#         plt.xticks(np.arange(1, len(n_max_depths)+1), np.arange(min_max_depth_parameter,max_max_depth_parameter+1),\n",
    "#                    fontsize=20, rotation=90)\n",
    "#         plt.xlabel('Número máximo de profundidade', fontsize=30)\n",
    "#         plt.yticks(fontsize=30)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a árvore final\n",
    "\n",
    "path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "dt_final_balanceado = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8)\n",
    "dt_final_balanceado.fit(train_data_b_4, train_target_b_4)\n",
    "joblib.dump(dt_final_balanceado, \n",
    "            path_arquivos+'arvore-final-abordagem-4-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl') # Salvando a árvore final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final_balanceado = joblib.load(path_arquivos+'arvore-final-abordagem-4-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.pkl')\n",
    "\n",
    "exibir_resultados_finais(clf=dt_final_balanceado, \n",
    "                         test_data=test_data_b_4, \n",
    "                         test_target=test_target_b_4, \n",
    "                         id_abordagem=4, \n",
    "                         str_balanceamento='balanceado', \n",
    "                         fracao_dataset=0.1,\n",
    "                         path_arquivos=path_arquivos,\n",
    "                         tipo_classificador='arvore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classificando o conjunto de teste\n",
    "\n",
    "# predicoes = dt_final_balanceado.predict(test_data_b_4)\n",
    "\n",
    "# # Salvando a árvore treinada graficamente\n",
    "\n",
    "# path_arquivos = 'Classificadores/Arvores-decisao/'\n",
    "\n",
    "# export_graphviz(dt_final_balanceado, \n",
    "#                 out_file=path_arquivos+'arvore-final-abordagem-4-balanceado-dataset-'+str(int(fracao_dataset*100))+'pct.dot', \n",
    "#                 feature_names=test_data_b_4.columns,  \n",
    "#                 class_names=['Less than or equal to', 'More than'],  \n",
    "#                 filled=True, rounded=True,  \n",
    "#                 special_characters=True)  \n",
    "\n",
    "# # Avaliando o desempenho\n",
    "\n",
    "# # Matriz de confusão\n",
    "\n",
    "# cfs_mtx = confusion_matrix(test_target_b_4, predicoes)\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# ax = sns.heatmap(cfs_mtx, \n",
    "#                  xticklabels=['<=50K', '>50K'], \n",
    "#                  yticklabels=['<=50K', '>50K'], \n",
    "#                  annot=cfs_mtx,\n",
    "#                  fmt='d',\n",
    "#                  cbar=None)\n",
    "\n",
    "# ax.set_xlabel('Predito', labelpad=20, fontsize=20)\n",
    "# ax.set_ylabel('Real', labelpad=20, fontsize=20)\n",
    "# ax.set_title('Matriz de Confusão')\n",
    "    \n",
    "# # plot_confusion_matrix(cfs_mtx, ['<=50K', '>50K'], normalize=False)\n",
    "# plt.show()\n",
    "\n",
    "# acc = accuracy_score(test_target_b_4, predicoes)\n",
    "# pre = precision_score(test_target_b_4, predicoes)\n",
    "# rec = recall_score(test_target_b_4, predicoes)\n",
    "# roc_auc = roc_auc_score(test_target_b_4, predicoes)\n",
    "# prc_auc = average_precision_score(test_target_b_4, predicoes)\n",
    "\n",
    "# print('Acurácia: %.3f %%' % (acc*100))\n",
    "# print('Precisão: %.3f %%' % (pre*100))\n",
    "# print('Recall: %.3f %%' % (rec*100))\n",
    "# print('ROC AUC: %.3f %%' % (roc_auc*100))\n",
    "# print('PRC AUC: %.3f %%' % (prc_auc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências Bibliográficas\n",
    "\n",
    "[1] (Online) UCI Machine Learning Repository: Census Income Dataset. Disponível em https://archive.ics.uci.edu/ml/datasets/Census+Income. Último acesso: 21/03/2018 às 00:22 horas.<br>\n",
    "\n",
    "[2] (Online) UCI Machine Learning Repository: Census Income KDD. Disponível em https://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD). Último acesso: 21/03/2018 às 01:30 horas.<br>\n",
    "\n",
    "[3] (Online) Classifying Income data from Census 1994 Data. Disponível em https://cseweb.ucsd.edu/~jmcauley/cse190/reports/sp15/024.pdf. Último acesso: 21/03/2018 às 01:32 horas.<br>\n",
    "\n",
    "[4] Ristanoski, Goce & Liu, Wei & Bailey, James. (2013). Discrimination aware classification for imbalanced datasets. International Conference on Information and Knowledge Management, Proceedings. 1529-1532. 10.1145/2505515.2507836.<br>\n",
    "\n",
    "[5] Hunter, John D. \"Matplotlib: A 2D graphics environment.\" Computing in science & engineering 9.3 (2007): 90-95.\n",
    "\n",
    "[6] (Online) Esperança de vida. Disponível em https://pt.wikipedia.org/wiki/Esperan%C3%A7a_de_vida. Último acesso: 23/04/2018 às 16:05 horas.<br>\n",
    "\n",
    "[7] (Online) Vital Statistics of the United States, 1994, Preprint of Volume II, Mortality, Part A, Section 6. https://www.cdc.gov/nchs/data/lifetables/life94_2.pdf. Último acesso: 23/04/2018 às 16:05 horas.<br>\n",
    "\n",
    "[8] An Introduction to ROC Analysis, Tom Fawcett, 2005, Pattern Recognition Letters 27. Disponível em: http://people.inf.elte.hu/kiss/11dwhdm/roc.pdf<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
